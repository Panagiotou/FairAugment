{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook contains simulations for constructing and evaluating the max-entropy distributions for small version of Compas dataset and Adult dataset\n",
    "\n",
    "The code is based on the following paper:\n",
    "\n",
    "**Data preprocessing to mitigate bias: A maximum-entropy based approach** <br>\n",
    "L.Elisa Celis, Vijay Keswani, Nisheeth K. Vishnoi <br>\n",
    "ICML 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<class 'str'>, <class 'bytes'>]\n",
      "[<class 'bool'>, <class 'numpy.bool_'>]\n",
      "[<class 'bool'>, <class 'numpy.bool_'>, numpy.unsignedinteger[typing.Any]]\n",
      "[<class 'bool'>, <class 'numpy.bool_'>, <class 'int'>, numpy.integer[typing.Any]]\n",
      "[<class 'bool'>, <class 'numpy.bool_'>, <class 'int'>, numpy.integer[typing.Any], <class 'float'>, numpy.floating[typing.Any]]\n",
      "[<class 'bool'>, <class 'numpy.bool_'>, <class 'int'>, numpy.integer[typing.Any], <class 'float'>, numpy.floating[typing.Any], <class 'complex'>, numpy.complexfloating[typing.Any, typing.Any]]\n",
      "[<class 'bool'>, <class 'numpy.bool_'>, <class 'int'>, numpy.integer[typing.Any], <class 'numpy.timedelta64'>]\n",
      "[<class 'int'>, <class 'float'>, <class 'complex'>, numpy.number[typing.Any], <class 'numpy.bool_'>]\n",
      "[<class 'int'>, <class 'float'>, <class 'complex'>, <class 'str'>, <class 'bytes'>, <class 'numpy.generic'>]\n",
      "[tuple[typing.Any, ...], <class 'numpy.void'>]\n",
      "[<class 'typing.SupportsIndex'>, collections.abc.Sequence[typing.SupportsIndex]]\n",
      "[numpy.dtype[~_SCT], type[~_SCT], numpy._typing._dtype_like._SupportsDType[numpy.dtype]]\n",
      "[tuple[typing.Any, int], tuple[typing.Any, typing.Union[typing.SupportsIndex, collections.abc.Sequence]], list[typing.Any], <class 'numpy._typing._dtype_like._DTypeDict'>, tuple[typing.Any, typing.Any]]\n",
      "[numpy.dtype[typing.Any], <class 'NoneType'>, type[typing.Any], numpy._typing._dtype_like._SupportsDType[numpy.dtype], <class 'str'>, tuple[typing.Any, int], tuple[typing.Any, typing.Union[typing.SupportsIndex, collections.abc.Sequence]], list[typing.Any], <class 'numpy._typing._dtype_like._DTypeDict'>, tuple[typing.Any, typing.Any]]\n",
      "[type[bool], type[numpy.bool_], numpy.dtype[numpy.bool_], numpy._typing._dtype_like._SupportsDType[numpy.dtype], typing.Literal['?', '=?', '<?', '>?', 'bool', 'bool_', 'bool8']]\n",
      "[type[numpy.unsignedinteger], numpy.dtype[numpy.unsignedinteger], numpy._typing._dtype_like._SupportsDType[numpy.dtype], typing.Literal['uint8', 'u1', '=u1', '<u1', '>u1'], typing.Literal['uint16', 'u2', '=u2', '<u2', '>u2'], typing.Literal['uint32', 'u4', '=u4', '<u4', '>u4'], typing.Literal['uint64', 'u8', '=u8', '<u8', '>u8'], typing.Literal['ubyte', 'B', '=B', '<B', '>B'], typing.Literal['ushort', 'H', '=H', '<H', '>H'], typing.Literal['uintc', 'I', '=I', '<I', '>I'], typing.Literal['uintp', 'uint0', 'P', '=P', '<P', '>P'], typing.Literal['ulong', 'uint', 'L', '=L', '<L', '>L'], typing.Literal['ulonglong', 'Q', '=Q', '<Q', '>Q']]\n",
      "[type[int], type[numpy.signedinteger], numpy.dtype[numpy.signedinteger], numpy._typing._dtype_like._SupportsDType[numpy.dtype], typing.Literal['int8', 'i1', '=i1', '<i1', '>i1'], typing.Literal['int16', 'i2', '=i2', '<i2', '>i2'], typing.Literal['int32', 'i4', '=i4', '<i4', '>i4'], typing.Literal['int64', 'i8', '=i8', '<i8', '>i8'], typing.Literal['byte', 'b', '=b', '<b', '>b'], typing.Literal['short', 'h', '=h', '<h', '>h'], typing.Literal['intc', 'i', '=i', '<i', '>i'], typing.Literal['intp', 'int0', 'p', '=p', '<p', '>p'], typing.Literal['long', 'int', 'int_', 'l', '=l', '<l', '>l'], typing.Literal['longlong', 'q', '=q', '<q', '>q']]\n",
      "[type[float], type[numpy.floating], numpy.dtype[numpy.floating], numpy._typing._dtype_like._SupportsDType[numpy.dtype], typing.Literal['float16', 'f2', '=f2', '<f2', '>f2'], typing.Literal['float32', 'f4', '=f4', '<f4', '>f4'], typing.Literal['float64', 'f8', '=f8', '<f8', '>f8'], typing.Literal['half', 'e', '=e', '<e', '>e'], typing.Literal['single', 'f', '=f', '<f', '>f'], typing.Literal['double', 'float', 'float_', 'd', '=d', '<d', '>d'], typing.Literal['longdouble', 'longfloat', 'g', '=g', '<g', '>g']]\n",
      "[type[complex], type[numpy.complexfloating], numpy.dtype[numpy.complexfloating], numpy._typing._dtype_like._SupportsDType[numpy.dtype], typing.Literal['complex64', 'c8', '=c8', '<c8', '>c8'], typing.Literal['complex128', 'c16', '=c16', '<c16', '>c16'], typing.Literal['csingle', 'singlecomplex', 'F', '=F', '<F', '>F'], typing.Literal['cdouble', 'complex', 'complex_', 'cfloat', 'D', '=D', '<D', '>D'], typing.Literal['clongdouble', 'clongfloat', 'longcomplex', 'G', '=G', '<G', '>G']]\n",
      "[type[numpy.timedelta64], numpy.dtype[numpy.timedelta64], numpy._typing._dtype_like._SupportsDType[numpy.dtype], typing.Literal['timedelta64', '=timedelta64', '<timedelta64', '>timedelta64', 'timedelta64[Y]', '=timedelta64[Y]', '<timedelta64[Y]', '>timedelta64[Y]', 'timedelta64[M]', '=timedelta64[M]', '<timedelta64[M]', '>timedelta64[M]', 'timedelta64[W]', '=timedelta64[W]', '<timedelta64[W]', '>timedelta64[W]', 'timedelta64[D]', '=timedelta64[D]', '<timedelta64[D]', '>timedelta64[D]', 'timedelta64[h]', '=timedelta64[h]', '<timedelta64[h]', '>timedelta64[h]', 'timedelta64[m]', '=timedelta64[m]', '<timedelta64[m]', '>timedelta64[m]', 'timedelta64[s]', '=timedelta64[s]', '<timedelta64[s]', '>timedelta64[s]', 'timedelta64[ms]', '=timedelta64[ms]', '<timedelta64[ms]', '>timedelta64[ms]', 'timedelta64[us]', '=timedelta64[us]', '<timedelta64[us]', '>timedelta64[us]', 'timedelta64[ns]', '=timedelta64[ns]', '<timedelta64[ns]', '>timedelta64[ns]', 'timedelta64[ps]', '=timedelta64[ps]', '<timedelta64[ps]', '>timedelta64[ps]', 'timedelta64[fs]', '=timedelta64[fs]', '<timedelta64[fs]', '>timedelta64[fs]', 'timedelta64[as]', '=timedelta64[as]', '<timedelta64[as]', '>timedelta64[as]', 'm', '=m', '<m', '>m', 'm8', '=m8', '<m8', '>m8', 'm8[Y]', '=m8[Y]', '<m8[Y]', '>m8[Y]', 'm8[M]', '=m8[M]', '<m8[M]', '>m8[M]', 'm8[W]', '=m8[W]', '<m8[W]', '>m8[W]', 'm8[D]', '=m8[D]', '<m8[D]', '>m8[D]', 'm8[h]', '=m8[h]', '<m8[h]', '>m8[h]', 'm8[m]', '=m8[m]', '<m8[m]', '>m8[m]', 'm8[s]', '=m8[s]', '<m8[s]', '>m8[s]', 'm8[ms]', '=m8[ms]', '<m8[ms]', '>m8[ms]', 'm8[us]', '=m8[us]', '<m8[us]', '>m8[us]', 'm8[ns]', '=m8[ns]', '<m8[ns]', '>m8[ns]', 'm8[ps]', '=m8[ps]', '<m8[ps]', '>m8[ps]', 'm8[fs]', '=m8[fs]', '<m8[fs]', '>m8[fs]', 'm8[as]', '=m8[as]', '<m8[as]', '>m8[as]']]\n",
      "[type[numpy.datetime64], numpy.dtype[numpy.datetime64], numpy._typing._dtype_like._SupportsDType[numpy.dtype], typing.Literal['datetime64', '=datetime64', '<datetime64', '>datetime64', 'datetime64[Y]', '=datetime64[Y]', '<datetime64[Y]', '>datetime64[Y]', 'datetime64[M]', '=datetime64[M]', '<datetime64[M]', '>datetime64[M]', 'datetime64[W]', '=datetime64[W]', '<datetime64[W]', '>datetime64[W]', 'datetime64[D]', '=datetime64[D]', '<datetime64[D]', '>datetime64[D]', 'datetime64[h]', '=datetime64[h]', '<datetime64[h]', '>datetime64[h]', 'datetime64[m]', '=datetime64[m]', '<datetime64[m]', '>datetime64[m]', 'datetime64[s]', '=datetime64[s]', '<datetime64[s]', '>datetime64[s]', 'datetime64[ms]', '=datetime64[ms]', '<datetime64[ms]', '>datetime64[ms]', 'datetime64[us]', '=datetime64[us]', '<datetime64[us]', '>datetime64[us]', 'datetime64[ns]', '=datetime64[ns]', '<datetime64[ns]', '>datetime64[ns]', 'datetime64[ps]', '=datetime64[ps]', '<datetime64[ps]', '>datetime64[ps]', 'datetime64[fs]', '=datetime64[fs]', '<datetime64[fs]', '>datetime64[fs]', 'datetime64[as]', '=datetime64[as]', '<datetime64[as]', '>datetime64[as]', 'M', '=M', '<M', '>M', 'M8', '=M8', '<M8', '>M8', 'M8[Y]', '=M8[Y]', '<M8[Y]', '>M8[Y]', 'M8[M]', '=M8[M]', '<M8[M]', '>M8[M]', 'M8[W]', '=M8[W]', '<M8[W]', '>M8[W]', 'M8[D]', '=M8[D]', '<M8[D]', '>M8[D]', 'M8[h]', '=M8[h]', '<M8[h]', '>M8[h]', 'M8[m]', '=M8[m]', '<M8[m]', '>M8[m]', 'M8[s]', '=M8[s]', '<M8[s]', '>M8[s]', 'M8[ms]', '=M8[ms]', '<M8[ms]', '>M8[ms]', 'M8[us]', '=M8[us]', '<M8[us]', '>M8[us]', 'M8[ns]', '=M8[ns]', '<M8[ns]', '>M8[ns]', 'M8[ps]', '=M8[ps]', '<M8[ps]', '>M8[ps]', 'M8[fs]', '=M8[fs]', '<M8[fs]', '>M8[fs]', 'M8[as]', '=M8[as]', '<M8[as]', '>M8[as]']]\n",
      "[type[str], type[numpy.str_], numpy.dtype[numpy.str_], numpy._typing._dtype_like._SupportsDType[numpy.dtype], typing.Literal['str', 'str_', 'str0', 'unicode', 'unicode_', 'U', '=U', '<U', '>U']]\n",
      "[type[bytes], type[numpy.bytes_], numpy.dtype[numpy.bytes_], numpy._typing._dtype_like._SupportsDType[numpy.dtype], typing.Literal['bytes', 'bytes_', 'bytes0', 'S', '=S', '<S', '>S']]\n",
      "[type[numpy.void], numpy.dtype[numpy.void], numpy._typing._dtype_like._SupportsDType[numpy.dtype], typing.Literal['void', 'void0', 'V', '=V', '<V', '>V'], tuple[typing.Any, int], tuple[typing.Any, typing.Union[typing.SupportsIndex, collections.abc.Sequence]], list[typing.Any], <class 'numpy._typing._dtype_like._DTypeDict'>, tuple[typing.Any, typing.Any]]\n",
      "[<class 'type'>, numpy.dtype[numpy.object_], numpy._typing._dtype_like._SupportsDType[numpy.dtype], typing.Literal['object', 'object_', 'O', '=O', '<O', '>O']]\n",
      "[type[bool], type[numpy.bool_], numpy.dtype[numpy.bool_], numpy._typing._dtype_like._SupportsDType[numpy.dtype], typing.Literal['?', '=?', '<?', '>?', 'bool', 'bool_', 'bool8'], type[numpy.unsignedinteger], numpy.dtype[numpy.unsignedinteger], numpy._typing._dtype_like._SupportsDType[numpy.dtype], typing.Literal['uint8', 'u1', '=u1', '<u1', '>u1'], typing.Literal['uint16', 'u2', '=u2', '<u2', '>u2'], typing.Literal['uint32', 'u4', '=u4', '<u4', '>u4'], typing.Literal['uint64', 'u8', '=u8', '<u8', '>u8'], typing.Literal['ubyte', 'B', '=B', '<B', '>B'], typing.Literal['ushort', 'H', '=H', '<H', '>H'], typing.Literal['uintc', 'I', '=I', '<I', '>I'], typing.Literal['uintp', 'uint0', 'P', '=P', '<P', '>P'], typing.Literal['ulong', 'uint', 'L', '=L', '<L', '>L'], typing.Literal['ulonglong', 'Q', '=Q', '<Q', '>Q'], type[int], type[numpy.signedinteger], numpy.dtype[numpy.signedinteger], numpy._typing._dtype_like._SupportsDType[numpy.dtype], typing.Literal['int8', 'i1', '=i1', '<i1', '>i1'], typing.Literal['int16', 'i2', '=i2', '<i2', '>i2'], typing.Literal['int32', 'i4', '=i4', '<i4', '>i4'], typing.Literal['int64', 'i8', '=i8', '<i8', '>i8'], typing.Literal['byte', 'b', '=b', '<b', '>b'], typing.Literal['short', 'h', '=h', '<h', '>h'], typing.Literal['intc', 'i', '=i', '<i', '>i'], typing.Literal['intp', 'int0', 'p', '=p', '<p', '>p'], typing.Literal['long', 'int', 'int_', 'l', '=l', '<l', '>l'], typing.Literal['longlong', 'q', '=q', '<q', '>q'], type[float], type[numpy.floating], numpy.dtype[numpy.floating], numpy._typing._dtype_like._SupportsDType[numpy.dtype], typing.Literal['float16', 'f2', '=f2', '<f2', '>f2'], typing.Literal['float32', 'f4', '=f4', '<f4', '>f4'], typing.Literal['float64', 'f8', '=f8', '<f8', '>f8'], typing.Literal['half', 'e', '=e', '<e', '>e'], typing.Literal['single', 'f', '=f', '<f', '>f'], typing.Literal['double', 'float', 'float_', 'd', '=d', '<d', '>d'], typing.Literal['longdouble', 'longfloat', 'g', '=g', '<g', '>g'], type[complex], type[numpy.complexfloating], numpy.dtype[numpy.complexfloating], numpy._typing._dtype_like._SupportsDType[numpy.dtype], typing.Literal['complex64', 'c8', '=c8', '<c8', '>c8'], typing.Literal['complex128', 'c16', '=c16', '<c16', '>c16'], typing.Literal['csingle', 'singlecomplex', 'F', '=F', '<F', '>F'], typing.Literal['cdouble', 'complex', 'complex_', 'cfloat', 'D', '=D', '<D', '>D'], typing.Literal['clongdouble', 'clongfloat', 'longcomplex', 'G', '=G', '<G', '>G']]\n",
      "[~_T, collections.abc.Sequence[~_T], collections.abc.Sequence[collections.abc.Sequence[~_T]], collections.abc.Sequence[collections.abc.Sequence[collections.abc.Sequence[~_T]]], collections.abc.Sequence[collections.abc.Sequence[collections.abc.Sequence[collections.abc.Sequence[~_T]]]]]\n",
      "[numpy._typing._array_like._SupportsArray[numpy.dtype], numpy._typing._nested_sequence._NestedSequence[numpy._typing._array_like._SupportsArray[numpy.dtype]]]\n",
      "[numpy._typing._array_like._SupportsArray[~_DType], numpy._typing._nested_sequence._NestedSequence[numpy._typing._array_like._SupportsArray[~_DType]], ~_T, numpy._typing._nested_sequence._NestedSequence[~_T]]\n",
      "[<class 'bool'>, <class 'int'>, <class 'float'>, <class 'complex'>, <class 'str'>, <class 'bytes'>]\n",
      "[numpy._typing._array_like._SupportsArray[numpy.dtype], numpy._typing._nested_sequence._NestedSequence[numpy._typing._array_like._SupportsArray[numpy.dtype]], <class 'bool'>, <class 'int'>, <class 'float'>, <class 'complex'>, <class 'str'>, <class 'bytes'>, numpy._typing._nested_sequence._NestedSequence[typing.Union[bool, int, float, complex, str, bytes]]]\n",
      "[numpy._typing._array_like._SupportsArray[numpy.dtype], numpy._typing._nested_sequence._NestedSequence[numpy._typing._array_like._SupportsArray[numpy.dtype]], <class 'bool'>, numpy._typing._nested_sequence._NestedSequence[bool]]\n",
      "[<class 'numpy.bool_'>, numpy.unsignedinteger[typing.Any]]\n",
      "[numpy._typing._array_like._SupportsArray[numpy.dtype], numpy._typing._nested_sequence._NestedSequence[numpy._typing._array_like._SupportsArray[numpy.dtype]], <class 'bool'>, numpy._typing._nested_sequence._NestedSequence[bool]]\n",
      "[<class 'numpy.bool_'>, numpy.integer[typing.Any]]\n",
      "[<class 'bool'>, <class 'int'>]\n",
      "[numpy._typing._array_like._SupportsArray[numpy.dtype], numpy._typing._nested_sequence._NestedSequence[numpy._typing._array_like._SupportsArray[numpy.dtype]], <class 'bool'>, <class 'int'>, numpy._typing._nested_sequence._NestedSequence[typing.Union[bool, int]]]\n",
      "[<class 'numpy.bool_'>, numpy.integer[typing.Any], numpy.floating[typing.Any]]\n",
      "[<class 'bool'>, <class 'int'>, <class 'float'>]\n",
      "[numpy._typing._array_like._SupportsArray[numpy.dtype], numpy._typing._nested_sequence._NestedSequence[numpy._typing._array_like._SupportsArray[numpy.dtype]], <class 'bool'>, <class 'int'>, <class 'float'>, numpy._typing._nested_sequence._NestedSequence[typing.Union[bool, int, float]]]\n",
      "[<class 'numpy.bool_'>, numpy.integer[typing.Any], numpy.floating[typing.Any], numpy.complexfloating[typing.Any, typing.Any]]\n",
      "[<class 'bool'>, <class 'int'>, <class 'float'>, <class 'complex'>]\n",
      "[numpy._typing._array_like._SupportsArray[numpy.dtype], numpy._typing._nested_sequence._NestedSequence[numpy._typing._array_like._SupportsArray[numpy.dtype]], <class 'bool'>, <class 'int'>, <class 'float'>, <class 'complex'>, numpy._typing._nested_sequence._NestedSequence[typing.Union[bool, int, float, complex]]]\n",
      "[<class 'numpy.bool_'>, numpy.number[typing.Any]]\n",
      "[numpy._typing._array_like._SupportsArray[numpy.dtype], numpy._typing._nested_sequence._NestedSequence[numpy._typing._array_like._SupportsArray[numpy.dtype]], <class 'bool'>, <class 'int'>, <class 'float'>, <class 'complex'>, numpy._typing._nested_sequence._NestedSequence[typing.Union[bool, int, float, complex]]]\n",
      "[<class 'numpy.bool_'>, numpy.integer[typing.Any], <class 'numpy.timedelta64'>]\n",
      "[numpy._typing._array_like._SupportsArray[numpy.dtype], numpy._typing._nested_sequence._NestedSequence[numpy._typing._array_like._SupportsArray[numpy.dtype]], <class 'bool'>, <class 'int'>, numpy._typing._nested_sequence._NestedSequence[typing.Union[bool, int]]]\n",
      "[numpy._typing._array_like._SupportsArray[numpy.dtype], numpy._typing._nested_sequence._NestedSequence[numpy._typing._array_like._SupportsArray[numpy.dtype]]]\n",
      "[numpy._typing._array_like._SupportsArray[numpy.dtype], numpy._typing._nested_sequence._NestedSequence[numpy._typing._array_like._SupportsArray[numpy.dtype]]]\n",
      "[numpy._typing._array_like._SupportsArray[numpy.dtype], numpy._typing._nested_sequence._NestedSequence[numpy._typing._array_like._SupportsArray[numpy.dtype]]]\n",
      "[numpy._typing._array_like._SupportsArray[numpy.dtype], numpy._typing._nested_sequence._NestedSequence[numpy._typing._array_like._SupportsArray[numpy.dtype]], <class 'str'>, numpy._typing._nested_sequence._NestedSequence[str]]\n",
      "[numpy._typing._array_like._SupportsArray[numpy.dtype], numpy._typing._nested_sequence._NestedSequence[numpy._typing._array_like._SupportsArray[numpy.dtype]], <class 'bytes'>, numpy._typing._nested_sequence._NestedSequence[bytes]]\n",
      "[numpy._typing._array_like._SupportsArray[numpy.dtype], numpy._typing._nested_sequence._NestedSequence[numpy._typing._array_like._SupportsArray[numpy.dtype]], <class 'int'>, numpy._typing._nested_sequence._NestedSequence[int]]\n",
      "[numpy._typing._array_like._SupportsArray[numpy.dtype], numpy._typing._nested_sequence._NestedSequence[numpy._typing._array_like._SupportsArray[numpy.dtype]], <class 'numpy._typing._array_like._UnknownType'>, numpy._typing._nested_sequence._NestedSequence[numpy._typing._array_like._UnknownType]]\n",
      "[typing.List[typing.Any], ~_T]\n",
      "[<class 'str'>, typing.List[str]]\n",
      "[<class 'str'>, ~_T]\n",
      "[ForwardRef('Distribution'), <class 'NoneType'>]\n",
      "[<class 'setuptools.extern.packaging._structures.InfinityType'>, <class 'setuptools.extern.packaging._structures.NegativeInfinityType'>]\n",
      "[<class 'setuptools.extern.packaging._structures.InfinityType'>, <class 'setuptools.extern.packaging._structures.NegativeInfinityType'>, typing.Tuple[str, int]]\n",
      "[<class 'setuptools.extern.packaging._structures.InfinityType'>, <class 'setuptools.extern.packaging._structures.NegativeInfinityType'>, <class 'int'>, <class 'str'>]\n",
      "[<class 'setuptools.extern.packaging._structures.InfinityType'>, <class 'setuptools.extern.packaging._structures.NegativeInfinityType'>, <class 'int'>, <class 'str'>, typing.Tuple[typing.Union[setuptools.extern.packaging._structures.InfinityType, setuptools.extern.packaging._structures.NegativeInfinityType, int, str], str], typing.Tuple[setuptools.extern.packaging._structures.NegativeInfinityType, typing.Union[setuptools.extern.packaging._structures.InfinityType, setuptools.extern.packaging._structures.NegativeInfinityType, int, str]]]\n",
      "[<class 'setuptools.extern.packaging._structures.NegativeInfinityType'>, typing.Tuple[typing.Union[setuptools.extern.packaging._structures.InfinityType, setuptools.extern.packaging._structures.NegativeInfinityType, int, str, typing.Tuple[typing.Union[setuptools.extern.packaging._structures.InfinityType, setuptools.extern.packaging._structures.NegativeInfinityType, int, str], str], typing.Tuple[setuptools.extern.packaging._structures.NegativeInfinityType, typing.Union[setuptools.extern.packaging._structures.InfinityType, setuptools.extern.packaging._structures.NegativeInfinityType, int, str]]], ...]]\n",
      "[<class 'str'>, <class 'bytes'>, <class 'typing.SupportsInt'>]\n",
      "[<class 'setuptools.extern.packaging._structures.NegativeInfinityType'>, typing.Tuple[typing.Union[setuptools.extern.packaging._structures.InfinityType, setuptools.extern.packaging._structures.NegativeInfinityType, int, str, typing.Tuple[typing.Union[setuptools.extern.packaging._structures.InfinityType, setuptools.extern.packaging._structures.NegativeInfinityType, int, str], str], typing.Tuple[setuptools.extern.packaging._structures.NegativeInfinityType, typing.Union[setuptools.extern.packaging._structures.InfinityType, setuptools.extern.packaging._structures.NegativeInfinityType, int, str]]], ...], <class 'NoneType'>]\n",
      "[typing.Tuple[typing.Union[setuptools.extern.packaging._structures.InfinityType, setuptools.extern.packaging._structures.NegativeInfinityType, int, str]], <class 'NoneType'>]\n",
      "[<class 'str'>, <class 'os.PathLike'>]\n",
      "[<class 'setuptools._vendor.packaging._elffile.ELFFile'>, <class 'NoneType'>]\n",
      "[<class 'setuptools._vendor.packaging._musllinux._MuslVersion'>, <class 'NoneType'>]\n",
      "[<class 'int'>, <class 'str'>, <class 'NoneType'>]\n",
      "[typing.Sequence[int], <class 'NoneType'>]\n",
      "[typing.Iterable[str], <class 'NoneType'>]\n",
      "[typing.Tuple[int, int], <class 'NoneType'>]\n",
      "[typing.Tuple[()], typing.Tuple[int, str]]\n",
      "[<class 'setuptools.extern.packaging.version.Version'>, <class 'str'>]\n",
      "[<class 'bool'>, <class 'NoneType'>]\n",
      "[<class 'str'>, <class 'setuptools.extern.packaging.version.Version'>]\n",
      "[ForwardRef('SpecifierSet'), <class 'str'>]\n",
      "[<class 'setuptools.extern.packaging._parser.Variable'>, <class 'setuptools.extern.packaging._parser.Value'>]\n",
      "[typing.List[typing.Any], <class 'NoneType'>]\n",
      "[typing.List[str], typing.Any, <class 'str'>]\n",
      "[typing.Dict[str, str], <class 'NoneType'>]\n",
      "[typing.Tuple[int, int, int], <class 'NoneType'>]\n",
      "[<class 'datetime.date'>, <class 'NoneType'>]\n",
      "[<class 'dict'>, <class 'NoneType'>]\n",
      "[<class 'str'>, <class 'pathlib.Path'>]\n",
      "[<class 'str'>, typing.Iterable[str]]\n",
      "[<class 'str'>, <class 'os.PathLike'>, <class 'NoneType'>]\n",
      "[<class 'str'>, <class 'bytes'>, typing.Iterable[typing.Union[str, os.PathLike]]]\n",
      "[<class 'bytes'>, <class 'str'>, <class 'os.PathLike'>]\n",
      "[typing.Mapping[str, str], <class 'NoneType'>]\n",
      "[<class 'str'>, <class 'int'>]\n",
      "[typing.Callable, typing.Iterable[typing.Union[str, int]], <class 'str'>]\n",
      "[<class 'list'>, <class 'dict'>]\n",
      "[ForwardRef('Distribution'), ForwardRef('DistributionMetadata')]\n",
      "[<class 'os.PathLike'>, <class 'str'>]\n",
      "[<class 'dict'>, <class 'str'>]\n",
      "[<class 'str'>, typing.Callable[[ForwardRef('Distribution'), typing.Any, typing.Union[os.PathLike, str]], NoneType]]\n",
      "[typing.Tuple[str, typing.Type], <class 'NoneType'>]\n",
      "[<class 'list'>, <class 'NoneType'>]\n",
      "[typing.Dict[str, dict], <class 'NoneType'>]\n",
      "[typing.List[str], <class 'NoneType'>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[typing.Callable, <class 'NoneType'>]\n",
      "[<class 'pandas.util.version.InfinityType'>, <class 'pandas.util.version.NegativeInfinityType'>]\n",
      "[<class 'pandas.util.version.InfinityType'>, <class 'pandas.util.version.NegativeInfinityType'>, tuple[str, int]]\n",
      "[<class 'pandas.util.version.InfinityType'>, <class 'pandas.util.version.NegativeInfinityType'>, <class 'int'>, <class 'str'>]\n",
      "[<class 'pandas.util.version.InfinityType'>, <class 'pandas.util.version.NegativeInfinityType'>, <class 'int'>, <class 'str'>, tuple[typing.Union[pandas.util.version.InfinityType, pandas.util.version.NegativeInfinityType, int, str], str], tuple[pandas.util.version.NegativeInfinityType, typing.Union[pandas.util.version.InfinityType, pandas.util.version.NegativeInfinityType, int, str]]]\n",
      "[<class 'pandas.util.version.NegativeInfinityType'>, tuple[typing.Union[pandas.util.version.InfinityType, pandas.util.version.NegativeInfinityType, int, str, tuple, tuple], ...]]\n",
      "[tuple[int, tuple[int, ...], typing.Union[pandas.util.version.InfinityType, pandas.util.version.NegativeInfinityType, tuple], typing.Union[pandas.util.version.InfinityType, pandas.util.version.NegativeInfinityType, tuple], typing.Union[pandas.util.version.InfinityType, pandas.util.version.NegativeInfinityType, tuple], typing.Union[pandas.util.version.NegativeInfinityType, tuple]], tuple[int, tuple[str, ...]]]\n",
      "[ForwardRef('ExtensionArray'), <class 'numpy.ndarray'>]\n",
      "[ForwardRef('ExtensionArray'), <class 'numpy.ndarray'>, ForwardRef('Index'), ForwardRef('Series')]\n",
      "[ForwardRef('DatetimeArray'), ForwardRef('TimedeltaArray')]\n",
      "[ForwardRef('ExtensionArray'), <class 'numpy.ndarray'>, ForwardRef('Index'), ForwardRef('Series'), <class 'pandas._typing.SequenceNotStr'>, <class 'range'>]\n",
      "[<class 'str'>, <class 'float'>, <class 'bool'>]\n",
      "[ForwardRef('Period'), ForwardRef('Timestamp'), ForwardRef('Timedelta')]\n",
      "[ForwardRef('Period'), ForwardRef('Timestamp'), ForwardRef('Timedelta'), ForwardRef('Interval')]\n",
      "[<class 'str'>, <class 'float'>, <class 'bool'>, ForwardRef('Period'), ForwardRef('Timestamp'), ForwardRef('Timedelta'), ForwardRef('Interval'), <class 'numpy.datetime64'>, <class 'numpy.timedelta64'>, <class 'datetime.date'>]\n",
      "[<class 'int'>, <class 'str'>]\n",
      "[ForwardRef('Timestamp'), <class 'datetime.date'>, <class 'numpy.datetime64'>, <class 'numpy.int64'>, <class 'float'>, <class 'str'>]\n",
      "[typing.Literal['shift_forward', 'shift_backward', 'NaT', 'raise'], <class 'datetime.timedelta'>]\n",
      "[ForwardRef('Timedelta'), <class 'datetime.timedelta'>, <class 'numpy.timedelta64'>, <class 'numpy.int64'>, <class 'float'>, <class 'str'>]\n",
      "[<class 'str'>, <class 'datetime.tzinfo'>]\n",
      "[<class 'int'>, typing.Literal['index', 'columns', 'rows']]\n",
      "[<class 'collections.abc.Hashable'>, collections.abc.Sequence[collections.abc.Hashable]]\n",
      "[<class 'str'>, <class 'float'>, <class 'bool'>, <class 'list'>, <class 'dict'>]\n",
      "[<class 'str'>, <class 'float'>, <class 'bool'>, <class 'list'>, <class 'dict'>, <class 'NoneType'>]\n",
      "[<class 'str'>, ForwardRef('BaseOffset')]\n",
      "[<class 'int'>, <class 'numpy.ndarray'>, <class 'numpy.random._generator.Generator'>, <class 'numpy.random.bit_generator.BitGenerator'>, <class 'numpy.random.mtrand.RandomState'>]\n",
      "[<class 'str'>, <class 'complex'>, <class 'bool'>, <class 'object'>]\n",
      "[<class 'str'>, <class 'numpy.dtype'>, typing.Type[typing.Union[str, complex, bool, object]]]\n",
      "[ForwardRef('ExtensionDtype'), <class 'str'>, <class 'numpy.dtype'>, typing.Type[typing.Union[str, complex, bool, object]]]\n",
      "[ForwardRef('ExtensionDtype'), ForwardRef('npt.DTypeLike')]\n",
      "[ForwardRef('ExtensionDtype'), <class 'str'>, <class 'numpy.dtype'>, typing.Type[typing.Union[str, complex, bool, object]], dict[collections.abc.Hashable, typing.Union[ForwardRef('ExtensionDtype'), str, numpy.dtype, typing.Type[typing.Union[str, complex, bool, object]]]]]\n",
      "[<class 'numpy.dtype'>, ForwardRef('ExtensionDtype')]\n",
      "[<class 'bool'>, list[collections.abc.Hashable], list[list[collections.abc.Hashable]], dict[collections.abc.Hashable, list[collections.abc.Hashable]]]\n",
      "[collections.abc.Mapping[typing.Any, collections.abc.Hashable], typing.Callable[[typing.Any], collections.abc.Hashable]]\n",
      "[ForwardRef('Series'), ForwardRef('ExtensionArray'), <class 'numpy.ndarray'>, ForwardRef('Index'), ForwardRef('Series')]\n",
      "[typing.Callable[[ForwardRef('Series')], typing.Union[ForwardRef('Series'), ForwardRef('ExtensionArray'), numpy.ndarray, ForwardRef('Index')]], <class 'NoneType'>]\n",
      "[ForwardRef('Index'), ForwardRef('ExtensionArray'), <class 'numpy.ndarray'>, ForwardRef('Index'), ForwardRef('Series')]\n",
      "[typing.Callable[[ForwardRef('Index')], typing.Union[ForwardRef('Index'), ForwardRef('ExtensionArray'), numpy.ndarray, ForwardRef('Series')]], <class 'NoneType'>]\n",
      "[typing.Callable, <class 'str'>]\n",
      "[typing.Callable, <class 'str'>, list[typing.Union[typing.Callable, str]]]\n",
      "[typing.Callable, <class 'str'>, list[typing.Union[typing.Callable, str]], collections.abc.MutableMapping[collections.abc.Hashable, typing.Union[typing.Callable, str, list]]]\n",
      "[ForwardRef('Series'), ForwardRef('DataFrame'), ForwardRef('GroupBy'), ForwardRef('SeriesGroupBy'), ForwardRef('DataFrameGroupBy'), ForwardRef('BaseWindow'), ForwardRef('Resampler')]\n",
      "[<class 'str'>, ForwardRef('PathLike[str]')]\n",
      "[dict[str, typing.Any], <class 'NoneType'>]\n",
      "[typing.Literal['infer', 'gzip', 'bz2', 'zip', 'xz', 'zstd', 'tar'], dict[str, typing.Any]]\n",
      "[typing.Literal['infer', 'gzip', 'bz2', 'zip', 'xz', 'zstd', 'tar'], dict[str, typing.Any], <class 'NoneType'>]\n",
      "[list[typing.Callable], tuple[typing.Callable, ...], collections.abc.Mapping[typing.Union[str, int], typing.Callable]]\n",
      "[<class 'str'>, typing.Callable, ForwardRef('EngFormatter')]\n",
      "[<class 'str'>, <class 'int'>, collections.abc.Sequence[typing.Union[str, int]], collections.abc.Mapping[collections.abc.Hashable, typing.Union[str, int]]]\n",
      "[ForwardRef('ArrayManager'), ForwardRef('SingleArrayManager'), ForwardRef('BlockManager'), ForwardRef('SingleBlockManager')]\n",
      "[ForwardRef('SingleArrayManager'), ForwardRef('SingleBlockManager')]\n",
      "[ForwardRef('ArrayManager'), ForwardRef('BlockManager')]\n",
      "[<class 'int'>, <class 'numpy.integer'>]\n",
      "[<class 'slice'>, list[int], <class 'numpy.ndarray'>]\n",
      "[<class 'int'>, <class 'numpy.integer'>, <class 'slice'>, list[int], <class 'numpy.ndarray'>]\n",
      "[<class 'int'>, <class 'numpy.integer'>, <class 'slice'>, list[int], <class 'numpy.ndarray'>, tuple[typing.Union[int, numpy.integer, slice, list, numpy.ndarray], typing.Union[int, numpy.integer, slice, list, numpy.ndarray]]]\n",
      "[typing.Literal['left', 'right'], typing.Literal['both', 'neither']]\n",
      "[<class 'datetime.datetime'>, ForwardRef('NaTType')]\n",
      "[typing.Literal['ignore', 'raise'], typing.Literal['coerce']]\n",
      "[typing.Literal['backfill', 'bfill', 'ffill', 'pad'], typing.Literal['nearest']]\n",
      "[<class 'str'>, collections.abc.Sequence[float]]\n",
      "[ForwardRef('Timestamp'), typing.Literal['epoch', 'start', 'start_day', 'end', 'end_day']]\n",
      "[typing.Literal['infer', 'NaT', 'raise'], ForwardRef('npt.NDArray[np.bool_]')]\n",
      "[typing.Literal['pearson', 'kendall', 'spearman'], typing.Callable[[numpy.ndarray, numpy.ndarray], float]]\n",
      "[<class 'numpy.busdaycalendar'>, ForwardRef('AbstractHolidayCalendar')]\n",
      "[pandas._typing.SequenceNotStr[collections.abc.Hashable], <class 'range'>, ForwardRef('ExtensionArray'), <class 'numpy.ndarray'>, ForwardRef('Index'), ForwardRef('Series'), typing.Callable[[~HashableT], bool], <class 'NoneType'>]\n",
      "[ForwardRef('Period'), ForwardRef('Timestamp'), ForwardRef('Timedelta'), <class 'pandas._libs.tslibs.nattype.NaTType'>]\n",
      "[ForwardRef('DatetimeArray'), ForwardRef('TimedeltaArray'), <class 'numpy.ndarray'>]\n",
      "[<class 'pandas._libs.interval.Interval'>, <class 'float'>]\n",
      "[collections.abc.Mapping[str, str], collections.abc.Iterable[str]]\n",
      "[<class 'str'>, <class 'pandas._libs.missing.NAType'>]\n",
      "[<class 'list'>, <class 'tuple'>, ForwardRef('ExtensionArray'), <class 'numpy.ndarray'>, ForwardRef('Index'), ForwardRef('Series')]\n",
      "[<class 'float'>, <class 'str'>]\n",
      "[<class 'float'>, <class 'str'>, <class 'datetime.date'>, <class 'numpy.datetime64'>]\n",
      "[<class 'float'>, <class 'str'>, <class 'datetime.date'>, <class 'numpy.datetime64'>, <class 'list'>, <class 'tuple'>, ForwardRef('ExtensionArray'), <class 'numpy.ndarray'>, ForwardRef('Index'), ForwardRef('Series')]\n",
      "[list[typing.Union[float, str]], tuple[typing.Union[float, str], ...], ForwardRef('ExtensionArray'), <class 'numpy.ndarray'>, ForwardRef('Index'), ForwardRef('Series')]\n",
      "[<class 'pandas.core.tools.datetimes.FulldatetimeDict'>, ForwardRef('DataFrame')]\n",
      "[<class 'collections.abc.Hashable'>, list[collections.abc.Hashable], typing.Callable[[collections.abc.Hashable], collections.abc.Hashable], list[typing.Callable[[collections.abc.Hashable], collections.abc.Hashable]], collections.abc.Mapping[collections.abc.Hashable, collections.abc.Hashable]]\n",
      "[<class 'str'>, typing.Callable[..., typing.Any]]\n",
      "[<class 'int'>, <class 'float'>, <class 'str'>, <class 'bool'>, <class 'datetime.time'>, <class 'datetime.date'>, <class 'datetime.datetime'>, <class 'datetime.timedelta'>]\n",
      "[<class 'sklearn.externals._packaging._structures.InfinityType'>, <class 'sklearn.externals._packaging._structures.NegativeInfinityType'>]\n",
      "[<class 'sklearn.externals._packaging._structures.InfinityType'>, <class 'sklearn.externals._packaging._structures.NegativeInfinityType'>, typing.Tuple[str, int]]\n",
      "[<class 'sklearn.externals._packaging._structures.InfinityType'>, <class 'sklearn.externals._packaging._structures.NegativeInfinityType'>, <class 'int'>, <class 'str'>]\n",
      "[<class 'sklearn.externals._packaging._structures.InfinityType'>, <class 'sklearn.externals._packaging._structures.NegativeInfinityType'>, <class 'int'>, <class 'str'>, typing.Tuple[typing.Union[sklearn.externals._packaging._structures.InfinityType, sklearn.externals._packaging._structures.NegativeInfinityType, int, str], str], typing.Tuple[sklearn.externals._packaging._structures.NegativeInfinityType, typing.Union[sklearn.externals._packaging._structures.InfinityType, sklearn.externals._packaging._structures.NegativeInfinityType, int, str]]]\n",
      "[<class 'sklearn.externals._packaging._structures.NegativeInfinityType'>, typing.Tuple[typing.Union[sklearn.externals._packaging._structures.InfinityType, sklearn.externals._packaging._structures.NegativeInfinityType, int, str, typing.Tuple[typing.Union[sklearn.externals._packaging._structures.InfinityType, sklearn.externals._packaging._structures.NegativeInfinityType, int, str], str], typing.Tuple[sklearn.externals._packaging._structures.NegativeInfinityType, typing.Union[sklearn.externals._packaging._structures.InfinityType, sklearn.externals._packaging._structures.NegativeInfinityType, int, str]]], ...]]\n",
      "[typing.Tuple[int, typing.Tuple[int, ...], typing.Union[sklearn.externals._packaging._structures.InfinityType, sklearn.externals._packaging._structures.NegativeInfinityType, typing.Tuple[str, int]], typing.Union[sklearn.externals._packaging._structures.InfinityType, sklearn.externals._packaging._structures.NegativeInfinityType, typing.Tuple[str, int]], typing.Union[sklearn.externals._packaging._structures.InfinityType, sklearn.externals._packaging._structures.NegativeInfinityType, typing.Tuple[str, int]], typing.Union[sklearn.externals._packaging._structures.NegativeInfinityType, typing.Tuple[typing.Union[sklearn.externals._packaging._structures.InfinityType, sklearn.externals._packaging._structures.NegativeInfinityType, int, str, typing.Tuple[typing.Union[sklearn.externals._packaging._structures.InfinityType, sklearn.externals._packaging._structures.NegativeInfinityType, int, str], str], typing.Tuple[sklearn.externals._packaging._structures.NegativeInfinityType, typing.Union[sklearn.externals._packaging._structures.InfinityType, sklearn.externals._packaging._structures.NegativeInfinityType, int, str]]], ...]]], typing.Tuple[int, typing.Tuple[str, ...]]]\n",
      "[ForwardRef('LegacyVersion'), ForwardRef('Version')]\n",
      "[typing.Tuple[str, int], <class 'NoneType'>]\n",
      "[<class 'int'>, <class 'NoneType'>]\n",
      "[<class 'str'>, <class 'bytes'>, <class 'typing.SupportsInt'>]\n",
      "[<class 'sklearn.externals._packaging._structures.NegativeInfinityType'>, typing.Tuple[typing.Union[sklearn.externals._packaging._structures.InfinityType, sklearn.externals._packaging._structures.NegativeInfinityType, int, str, typing.Tuple[typing.Union[sklearn.externals._packaging._structures.InfinityType, sklearn.externals._packaging._structures.NegativeInfinityType, int, str], str], typing.Tuple[sklearn.externals._packaging._structures.NegativeInfinityType, typing.Union[sklearn.externals._packaging._structures.InfinityType, sklearn.externals._packaging._structures.NegativeInfinityType, int, str]]], ...], <class 'NoneType'>]\n",
      "[typing.Tuple[typing.Union[sklearn.externals._packaging._structures.InfinityType, sklearn.externals._packaging._structures.NegativeInfinityType, int, str]], <class 'NoneType'>]\n",
      "[typing.List[zmq.sugar.frame.Frame], typing.List[bytes]]\n",
      "[<class 'Exception'>, <class 'NoneType'>]\n",
      "[<class 'int'>, <class 'str'>]\n",
      "[typing.Tuple[int, int], <class 'NoneType'>]\n",
      "[typing.Dict, <class 'NoneType'>]\n",
      "[<class 'str'>, <class 'os.PathLike'>]\n",
      "[<class 'str'>, <class 'os.PathLike'>, <class 'NoneType'>]\n",
      "[<class 'str'>, typing.List]\n",
      "[<class 'str'>, typing.List, <class 'NoneType'>]\n",
      "[<class 'str'>, <class 'bool'>]\n",
      "No module named 'tensorflow': AdversarialDebiasing will be unavailable. To install, run:\n",
      "pip install 'aif360[AdversarialDebiasing]'\n",
      "[<class 'str'>, typing.Iterable[str]]\n",
      "[typing.Tuple[int, int], typing.Tuple[int]]\n",
      "[<class 'pyparsing.results.ParseResults'>, typing.Sequence[pyparsing.results.ParseResults]]\n",
      "[typing.Callable[[], typing.Any], typing.Callable[[pyparsing.results.ParseResults], typing.Any], typing.Callable[[int, pyparsing.results.ParseResults], typing.Any], typing.Callable[[str, int, pyparsing.results.ParseResults], typing.Any]]\n",
      "[typing.Callable[[], bool], typing.Callable[[pyparsing.results.ParseResults], bool], typing.Callable[[int, pyparsing.results.ParseResults], bool], typing.Callable[[str, int, pyparsing.results.ParseResults], bool]]\n",
      "[typing.Callable[[str, int, ForwardRef('ParserElement'), bool], NoneType], <class 'NoneType'>]\n",
      "[typing.Callable[[str, int, int, ForwardRef('ParserElement'), pyparsing.results.ParseResults, bool], NoneType], <class 'NoneType'>]\n",
      "[typing.Callable[[str, int, ForwardRef('ParserElement'), Exception, bool], NoneType], <class 'NoneType'>]\n",
      "[<class 'pyparsing.results.ParseResults'>, <class 'Exception'>]\n",
      "[<class 'int'>, <class 'NoneType'>]\n",
      "[typing.Set[str], <class 'str'>]\n",
      "[<class 'str'>, <class 'pathlib.Path'>, <class 'typing.TextIO'>]\n",
      "[<class 'str'>, typing.List[str]]\n",
      "[ForwardRef('ParserElement'), <class 'str'>]\n",
      "[ForwardRef('ParserElement'), <class 'str'>, <class 'NoneType'>]\n",
      "[typing.Callable[[str, pyparsing.results.ParseResults], str], <class 'NoneType'>]\n",
      "[<class 'typing.TextIO'>, <class 'NoneType'>]\n",
      "[<class 'typing.TextIO'>, <class 'pathlib.Path'>, <class 'str'>]\n",
      "[<enum 'RegexFlag'>, <class 'int'>]\n",
      "[<class 'pyparsing.core.ParserElement'>, <class 'str'>]\n",
      "[<class 'str'>, <class 'pyparsing.core.ParserElement'>]\n",
      "[<class 'pyparsing.core.ParserElement'>, <class 'str'>, <class 'NoneType'>]\n",
      "[<class 'pyparsing.core.ParserElement'>, <class 'NoneType'>]\n",
      "[typing.Iterable[str], <class 'str'>]\n",
      "[<class 'pyparsing.core.ParserElement'>, <class 'str'>, typing.Tuple[typing.Union[pyparsing.core.ParserElement, str], typing.Union[pyparsing.core.ParserElement, str]]]\n",
      "[typing.Callable[[], typing.Any], typing.Callable[[pyparsing.results.ParseResults], typing.Any], typing.Callable[[int, pyparsing.results.ParseResults], typing.Any], typing.Callable[[str, int, pyparsing.results.ParseResults], typing.Any], <class 'NoneType'>]\n",
      "[typing.Tuple[typing.Union[pyparsing.core.ParserElement, str, typing.Tuple[typing.Union[pyparsing.core.ParserElement, str], typing.Union[pyparsing.core.ParserElement, str]]], int, pyparsing.helpers.OpAssoc, typing.Union[typing.Callable[[], typing.Any], typing.Callable[[pyparsing.results.ParseResults], typing.Any], typing.Callable[[int, pyparsing.results.ParseResults], typing.Any], typing.Callable[[str, int, pyparsing.results.ParseResults], typing.Any], NoneType]], typing.Tuple[typing.Union[pyparsing.core.ParserElement, str, typing.Tuple[typing.Union[pyparsing.core.ParserElement, str], typing.Union[pyparsing.core.ParserElement, str]]], int, pyparsing.helpers.OpAssoc]]\n",
      "[<class 'str'>, os.PathLike[str]]\n",
      "[<class 'module'>, <class 'str'>]\n",
      "[<class 'module'>, <class 'str'>, <class 'NoneType'>]\n",
      "[<class 'importlib_resources.abc.ResourceReader'>, <class 'NoneType'>]\n",
      "No module named 'tensorflow': AdversarialDebiasing will be unavailable. To install, run:\n",
      "pip install 'aif360[AdversarialDebiasing]'\n",
      "No module named 'fairlearn': ExponentiatedGradientReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "No module named 'inFairness': SenSeI and SenSR will be unavailable. To install, run:\n",
      "pip install 'aif360[inFairness]'\n",
      "No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "[<class 'pandas.core.series.Series'>, <class 'pandas.core.frame.DataFrame'>]\n",
      "[<class 'str'>, <class 'float'>]\n",
      "[<class 'str'>, <class 'aif360.detectors.mdss.ScoringFunctions.ScoringFunction.ScoringFunction'>]\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "sys.path.append(\"..\")\n",
    "# This project requires the IBM AIF360 package for the datasets (https://github.com/ibm/aif360)\n",
    "\n",
    "import numpy as np\n",
    "from Fair_Max_Entropy_Distributions.FairMaxEnt.domain import Domain\n",
    "from Fair_Max_Entropy_Distributions.FairMaxEnt.memory import MemoryTrie\n",
    "from Fair_Max_Entropy_Distributions.FairMaxEnt.maximum_entropy_distribution import MaxEnt\n",
    "from Fair_Max_Entropy_Distributions.FairMaxEnt.fair_maximum_entropy import FairMaximumEntropy\n",
    "from Fair_Max_Entropy_Distributions.FairMaxEnt.fair_maximum_entropy import reweightSamples\n",
    "from Fair_Max_Entropy_Distributions.Codes.Utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm as tqdm\n",
    "# from tqdm import tqdm_notebook as tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the dataset\n",
    "\n",
    "Replace with Adult dataset for equivalent evaluation (load functions are present in Utils file). <br>\n",
    "The rest of the code (other than sensitive attribute index and domainarray) is mostly dataset non-specific. <br>\n",
    "Use notebook FairMaxEnt-expts-2 for large compas dataset expts. <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Data: 5 rows removed from CompasDataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/panagiotou/anaconda3/envs/p39/lib/python3.9/site-packages/aif360/algorithms/preprocessing/optim_preproc_helpers/data_preproc_functions.py:163: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  dfcutQ['sex'] = dfcutQ['sex'].replace({'Female': 1.0, 'Male': 0.0})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Domain in 11 with 6, 5278)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simpleDomain, simpleSamples = getSmallCompasDataset()\n",
    "simpleDomain, len(simpleSamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sex', 'race', 'age', 'priors_count', 'c_charge_degree', 'two_year_recid']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simpleDomain.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "domainArray = getSmallCompasDomain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example runs of max-entropy optimization program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The setup is done and now we can run the experiments <br>\n",
    "C - smoothing parameter <br>\n",
    "delta - error parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 0.1\n",
    "delta = 0\n",
    "\n",
    "sens_attr = simpleDomain.labels.index(\"race\")    # for Compas\n",
    "\n",
    "# labelIndex denotes the index of class label\n",
    "labelIndex = len(simpleSamples[0]) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5278, 11)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simpleSamples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sens_attr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fairness metrics, evaluated over the original raw dataset, have the following values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical Rate:  0.7471480065031378\n",
      "Representation Rate:  0.6623622047244094\n"
     ]
    }
   ],
   "source": [
    "print(\"Statistical Rate: \", getDisparateImpact(simpleSamples, sens_attr))\n",
    "print(\"Representation Rate: \", getGenderRatio(simpleSamples, sens_attr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we also need to calculate KL-divergence from empirical distribution of original dataset, we first find this distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0032834494455346e-07"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This utility evaluation procedure does not work for large COMPAS dataset, due to large size of domain.\n",
    "\n",
    "domain = getDomain(domainArray)\n",
    "rawDataDist = getDistribution(simpleSamples, domain) + np.array([0.0000001]*len(domain))\n",
    "\n",
    "getUtility(simpleSamples, rawDataDist, domain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We first look at max-entropy distribution using dataset mean and prior\n",
    "The prior in this case is $q_C^d$ and the expected value is mean of original dataset, $\\theta^d$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical Rate:  0.8025073266037122\n",
      "Representation Rate:  0.6666666666666666\n",
      "KL-divergence wrt raw data:  0.02270855976106769\n"
     ]
    }
   ],
   "source": [
    "maxEnt = FairMaximumEntropy(simpleDomain, simpleSamples, C, delta, labelIndex, reweight=False, weightedMean=False)\n",
    "dataset = maxEnt.sample(10000)\n",
    "\n",
    "print(\"Statistical Rate: \", getDisparateImpact(dataset, sens_attr))\n",
    "print(\"Representation Rate: \", getGenderRatio(dataset, sens_attr))\n",
    "print(\"KL-divergence wrt raw data: \", getUtility(dataset, rawDataDist, domain))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The raw dataset, in this case, is quite biased. Hence using just $q_C^d$ and $\\theta^d$ will not lead to a fair max-entropy distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next we can set different prior and expected values to debias the distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameter *reweight* can be set true if the re-weighted prior distribution (i.e., $q_C^w$) should be used.\n",
    "The parameter *weightedMean* can be set true if the re-weighted expected value should be used (i.e., $\\theta^w$).\n",
    "Using these, we get a max-entropy distribution that has high statistical and representation rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical Rate:  0.9810178549973025\n",
      "Representation Rate:  0.9657951641438962\n",
      "KL-divergence wrt raw data:  0.05349458280249288\n"
     ]
    }
   ],
   "source": [
    "maxEnt = FairMaximumEntropy(simpleDomain, simpleSamples, C, delta, 0,\n",
    "                                reweight=True, reweightXindices=[sens_attr],\n",
    "                                reweightYindices=[len(simpleSamples[0])-1], weightedMean=True)\n",
    "dataset = maxEnt.sample(10000)\n",
    "\n",
    "print(\"Statistical Rate: \", getDisparateImpact(dataset, sens_attr))\n",
    "print(\"Representation Rate: \", getGenderRatio(dataset, sens_attr))\n",
    "print(\"KL-divergence wrt raw data: \", getUtility(dataset, rawDataDist, domain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6616113744075829, 0.9381480330255939)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, testData = getTrainAndTestData(simpleSamples, 3)    \n",
    "getClfAccAndDI(dataset, testData, sens_attr, clf = DecisionTreeClassifier(random_state=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we *reweight* to be true, but *weightedMean* to be false, i.e., using fair prior but the expected value is the mean of the original dataset. With this combination, we get a distribution with high statistical rate but low representation rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical Rate:  0.9943290132963473\n",
      "Representation Rate:  0.6605778811026237\n",
      "KL-divergence wrt raw data:  0.03441313417136953\n"
     ]
    }
   ],
   "source": [
    "labelIndex = len(simpleSamples[0])-1\n",
    "maxEnt = FairMaximumEntropy(simpleDomain, simpleSamples, C, delta, sens_attr,\n",
    "                            reweight=True, reweightXindices=[sens_attr],\n",
    "                            reweightYindices=[labelIndex])\n",
    "\n",
    "dataset = maxEnt.sample(10000)\n",
    "print(\"Statistical Rate: \", getDisparateImpact(dataset, sens_attr))\n",
    "print(\"Representation Rate: \", getGenderRatio(dataset, sens_attr))\n",
    "print(\"KL-divergence wrt raw data: \", getUtility(dataset, rawDataDist, domain))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use $\\theta^b$, we need to set *alterMean* to be true. With this combination, we again get a distribution with high statistical rate and high representation rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical Rate:  0.9921182969283651\n",
      "Representation Rate:  0.9813750743015652\n",
      "KL-divergence wrt raw data:  0.0614629481869033\n",
      "CPU times: user 862 ms, sys: 1.67 ms, total: 864 ms\n",
      "Wall time: 862 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# The parameter alterMean can be set true if the balanced expected value should be used\n",
    "\n",
    "\n",
    "maxEnt = FairMaximumEntropy(simpleDomain, simpleSamples, C, delta, sens_attr,\n",
    "                                reweight=True, reweightXindices=[sens_attr],\n",
    "                                reweightYindices=[labelIndex], alterMean = True)\n",
    "\n",
    "dataset = maxEnt.sample(10000)\n",
    "print(\"Statistical Rate: \", getDisparateImpact(dataset, sens_attr))\n",
    "print(\"Representation Rate: \", getGenderRatio(dataset, sens_attr))\n",
    "print(\"KL-divergence wrt raw data: \", getUtility(dataset, rawDataDist, domain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 11)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 0., ..., 0., 1., 0.],\n",
       "       [0., 1., 0., ..., 1., 0., 1.],\n",
       "       [0., 0., 1., ..., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1., ..., 1., 0., 0.],\n",
       "       [1., 0., 0., ..., 1., 0., 0.],\n",
       "       [1., 1., 1., ..., 0., 1., 0.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dataset.shape)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiments in the paper\n",
    "In the paper, we report value after 5-fold cross-validation. For each fold, we do 100 simulations.\n",
    "We also provide results for different values of C. \n",
    "\n",
    "The max-entropy distribution computed below represent all possible choices of prior distribution, expected vector and parameter $C$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97463b5df4f84fe48a5044591c429a3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb36d5d3c2d741c8b96b82c0679d5946",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c7d39eb99e04357979333161be07c80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "058c7d30c90d4cc1b14ef32ef6fae3c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ced4e358a6f1450393c52eb408dc68f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1e76d9aad5b46b29425c81e4eb68974",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "maxEnts = {'maxEnt_unif_wt_unif_mean' : {}, \n",
    "                  'maxEnt_re_wt_unif_mean' : {}, \n",
    "                  'maxEnt_unif_wt_alt_mean' : {}, \n",
    "                  'maxEnt_re_wt_alt_mean' : {}, \n",
    "                  'maxEnt_unif_wt_wt_mean' : {}, \n",
    "                  'maxEnt_re_wt_wt_mean' : {}}\n",
    "\n",
    "for key in maxEnts.keys():\n",
    "    for D in range(11):\n",
    "        C = D/10.0\n",
    "        maxEnts[key][C] = {}\n",
    "        \n",
    "\n",
    "delta = 0\n",
    "labelIndex = len(simpleSamples[0]) - 1\n",
    "\n",
    "for fold in tqdm(range(5)):\n",
    "    \n",
    "    trainData, testData = getTrainAndTestData(simpleSamples, fold)\n",
    "    \n",
    "    for D in tqdm(range(11)):\n",
    "        C = D/10.0\n",
    "        key = \"{fold}_{C}\".format(fold=fold, C=C)\n",
    "        \n",
    "        \n",
    "        maxEnts['maxEnt_unif_wt_unif_mean'][C][fold] = FairMaximumEntropy(simpleDomain, trainData, \n",
    "                                          C, \n",
    "                                          delta, \n",
    "                                          sens_attr)\n",
    "        \n",
    "        \n",
    "        maxEnts['maxEnt_re_wt_unif_mean'][C][fold] = FairMaximumEntropy(simpleDomain, \n",
    "                                          trainData, \n",
    "                                          C, \n",
    "                                          delta, \n",
    "                                          sens_attr,\n",
    "                                          reweight=True, \n",
    "                                          reweightXindices=[sens_attr],\n",
    "                                          reweightYindices=[labelIndex])\n",
    "\n",
    "\n",
    "        maxEnts['maxEnt_unif_wt_alt_mean'][C][fold] = FairMaximumEntropy(simpleDomain, \n",
    "                                          trainData, \n",
    "                                          C, \n",
    "                                          delta, \n",
    "                                          sens_attr,\n",
    "                                          alterMean = True)\n",
    "\n",
    "        \n",
    "        maxEnts['maxEnt_re_wt_alt_mean'][C][fold] = FairMaximumEntropy(simpleDomain, trainData, C, delta, sens_attr,\n",
    "                                reweight=True, reweightXindices=[sens_attr],\n",
    "                                reweightYindices=[labelIndex], alterMean = True)\n",
    "\n",
    "        \n",
    "        maxEnts['maxEnt_unif_wt_wt_mean'][C][fold] = FairMaximumEntropy(simpleDomain, trainData, C, delta, sens_attr,\n",
    "                                weightedMean=True, reweightXindices=[sens_attr],\n",
    "                                reweightYindices=[labelIndex])\n",
    "\n",
    "            \n",
    "        maxEnts['maxEnt_re_wt_wt_mean'][C][fold] = FairMaximumEntropy(simpleDomain, trainData, C, delta, sens_attr,\n",
    "                                reweight=True, reweightXindices=[sens_attr],\n",
    "                                reweightYindices=[labelIndex], weightedMean=True)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these max-entropy distributions, we can sample 10000 elements to create a new dataset and compute the fairness-accuracy metrics of this dataset.\n",
    "We can also train a classifier on this new dataset and check the fairness and accuracy of the trained classifier on the test-fold of the original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds= 5\n",
    "repetitions = 1.369\n",
    "samples = 10000\n",
    "\n",
    "DIs, KLs, GRs, Accs, CDs = [], [], [], [], []\n",
    "for key in tqdm(maxEnts.keys()):\n",
    "    diForKey, klForKey, grForKey, accForKey, cdForKey = [], [], [], [], []\n",
    "    for D in tqdm(range(11)):\n",
    "        C = D/10.0\n",
    "        for fold in range(folds):\n",
    "            di, kl, gr, acc, cd = [] ,[], [], [], []\n",
    "            for _ in range(repetitions):\n",
    "                dataset = maxEnts[key][C][fold].sample(samples)\n",
    "            \n",
    "                di.append(getDisparateImpact(dataset, sens_attr))\n",
    "                kl.append(getUtility(dataset, rawDataDist, domain))\n",
    "                gr.append(getGenderRatio(dataset, sens_attr))\n",
    "                \n",
    "                _, testData = getTrainAndTestData(simpleSamples, fold)    \n",
    "                a1, cd1 = getClfAccAndDI(dataset, testData, sens_attr, clf = DecisionTreeClassifier(random_state=0))\n",
    "                acc.append(a1)\n",
    "                cd.append(cd1)\n",
    "            \n",
    "            diForKey = diForKey + di\n",
    "            klForKey = klForKey + kl\n",
    "            grForKey = grForKey + gr\n",
    "            accForKey = accForKey + acc\n",
    "            cdForKey = cdForKey + cd\n",
    "    DIs.append(diForKey)\n",
    "    KLs.append(klForKey)\n",
    "    GRs.append(grForKey)\n",
    "    Accs.append(accForKey)\n",
    "    CDs.append(cdForKey)\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plots below show the variation of the metrics with C and for different prior and expected value parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 4))\n",
    "cPlot(DIs, \"Data Statistical Rate\", title=\"Data Statistical Rate vs C\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 4))\n",
    "cPlot(GRs, \"Representation Rate\", title=\"Representation Rate vs C\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 4))\n",
    "cPlot(KLs, \"KL-divergence wrt raw datat\", title=\"Divergence vs C\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 4))\n",
    "cPlot(CDs, \"Classifier Statistical Rate\", title=\"Classifier fairness vs C\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 4))\n",
    "cPlot(Accs, \"Classifier Accuracy\", title=\"Classifier Accuracy vs C\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
