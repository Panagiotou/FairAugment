{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append(\"..\")\n",
    "from src.dataset import Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from definitions import *\n",
    "import copy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Suppress LightGBM categorical_feature warning\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"categorical_feature keyword has been found*\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"categorical_feature in param dict is overridden*\")\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, precision_score, recall_score\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset adult_fnlwgt_educational-num has ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country'] categorical and ['age', 'capital-gain', 'capital-loss', 'hours-per-week'] numerical columns.\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"adult\"\n",
    "\n",
    "\n",
    "dataset_name_latex = \"\\\\\"+dataset_name\n",
    "\n",
    "\n",
    "if dataset_name==\"credit\":\n",
    "    dataset_name_latex += \"dataset\"\n",
    "dataset_generator = Dataset(dataset_name)\n",
    "all_data = dataset_generator.original_dataframe.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tabfairgan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epochs TabFairGAN: 100%|██████████| 200/200 [03:02<00:00,  1.10it/s]\n",
      "Training epochs TabFairGAN: 100%|██████████| 200/200 [03:12<00:00,  1.04it/s]\n",
      "Training epochs TabFairGAN: 100%|██████████| 200/200 [03:14<00:00,  1.03it/s]\n",
      "Training epochs TabFairGAN: 100%|██████████| 200/200 [02:57<00:00,  1.13it/s]\n",
      "Training epochs TabFairGAN: 100%|██████████| 200/200 [03:04<00:00,  1.09it/s]\n",
      "Training epochs TabFairGAN: 100%|██████████| 200/200 [03:10<00:00,  1.05it/s]\n",
      "Training epochs TabFairGAN: 100%|██████████| 200/200 [02:54<00:00,  1.15it/s]\n",
      "Training epochs TabFairGAN: 100%|██████████| 200/200 [03:16<00:00,  1.02it/s]\n",
      "Training epochs TabFairGAN: 100%|██████████| 200/200 [03:14<00:00,  1.03it/s]\n"
     ]
    }
   ],
   "source": [
    "# generative_methods = [\"tabfairgan\", \"gaussian_copula\", \"ctgan\", \"tvae\", \"cart\", \"smote\"]\n",
    "generative_methods = [\"tabfairgan\"]\n",
    "num_folds = 3\n",
    "num_repeats = 3\n",
    "fit_times_all_mean = []\n",
    "fit_times_all_std = []\n",
    "sample_times_all_mean = []\n",
    "sample_times_all_std = []\n",
    "\n",
    "both_times_all_mean = []\n",
    "both_times_all_std = []\n",
    "\n",
    "size = 10000\n",
    "import time\n",
    "\n",
    "\n",
    "target = dataset_generator.target\n",
    "target_class_desired = dataset_generator.target_class_desired\n",
    "dtype_map = dataset_generator.dtype_map\n",
    "\n",
    "tab_fair_gan_args = {\"verbose\": False, \"protected_attributes\":[\"sex\"],\n",
    "                                        \"target\": target, \"target_class_desired\": target_class_desired}\n",
    "\n",
    "\n",
    "for generative_method in generative_methods:\n",
    "    print(generative_method)\n",
    "    target = dataset_generator.target\n",
    "    fit_times = []\n",
    "    sample_times = []\n",
    "    both_times = []\n",
    "    rkf = RepeatedKFold(n_splits=num_folds, n_repeats=num_repeats, random_state=42)\n",
    "    for i, (train_index, test_index) in enumerate(rkf.split(all_data)):    \n",
    "\n",
    "        data_train, data_test = all_data.loc[train_index], all_data.loc[test_index]\n",
    "        data_train_encoded = dataset_generator.encode(data_train, keep_dtypes=True)\n",
    "        data_test_encoded = dataset_generator.encode(data_test)\n",
    "\n",
    "\n",
    "        X_train_real = data_train.copy().drop(columns=[target])\n",
    "\n",
    "        y_train_real = data_train_encoded[target].copy().astype(\"int\")\n",
    "\n",
    "        class_split_df = X_train_real.copy()\n",
    "        class_split_df.drop('sex', axis=1, inplace=True)\n",
    "        start_time = time.time()\n",
    "\n",
    "        if generative_method==\"tvae\" or generative_method==\"ctgan\" or generative_method==\"gaussian_copula\":\n",
    "            split_synthesizer = dataset_generator.train_synthesizer(generative_method, class_split_df, encode=False, random_state=i) \n",
    "        elif generative_method==\"tabfairgan\":\n",
    "            split_synthesizer = TabFairGAN(seed=i, dtype_map=dtype_map, **tab_fair_gan_args)\n",
    "            split_synthesizer.fit(data_train)\n",
    "        else:\n",
    "            split_synthesizer = dataset_generator.train_synthesizer(generative_method, class_split_df, encode=True, random_state=i) \n",
    "        end_time = time.time()\n",
    "        time_taken1 = end_time - start_time\n",
    "        fit_times.append(time_taken1)\n",
    "        start_time = time.time()\n",
    "\n",
    "        if generative_method==\"tvae\" or generative_method==\"ctgan\" or generative_method==\"gaussian_copula\":\n",
    "            split_synthetic_data = dataset_generator.generate_data(split_synthesizer, num=size, name=generative_method, decode=False, random_state=i)\n",
    "        elif generative_method==\"tabfairgan\":\n",
    "            split_synthetic_data = split_synthesizer.generate(int(size))\n",
    "        else:\n",
    "            split_synthetic_data = dataset_generator.generate_data(split_synthesizer, num=size, random_state=i)\n",
    "        end_time = time.time()\n",
    "        time_taken = end_time - start_time\n",
    "        sample_times.append(time_taken)\n",
    "        both_times.append(time_taken1 + time_taken)\n",
    "\n",
    "    fit_times_all_mean.append(np.mean(fit_times))\n",
    "    fit_times_all_std.append(np.std(fit_times))\n",
    "\n",
    "    sample_times_all_mean.append(np.mean(sample_times))\n",
    "    sample_times_all_std.append(np.std(sample_times))\n",
    "\n",
    "    both_times_all_mean.append(np.mean(both_times))\n",
    "    both_times_all_std.append(np.std(both_times))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tabfairgan']\n",
      "[187.52189183235168]\n",
      "[7.641595471229717]\n",
      "[0.011350525750054253]\n",
      "[0.005235342892258026]\n",
      "[187.53324235810175]\n",
      "[7.6401043596181495]\n"
     ]
    }
   ],
   "source": [
    "print(generative_methods)\n",
    "print(fit_times_all_mean)\n",
    "print(fit_times_all_std)\n",
    "\n",
    "print(sample_times_all_mean)\n",
    "print(sample_times_all_std)\n",
    "\n",
    "print(both_times_all_mean)\n",
    "print(both_times_all_std)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "samplestructures",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
