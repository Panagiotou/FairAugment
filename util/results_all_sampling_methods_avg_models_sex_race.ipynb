{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "# Enable autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys \n",
    "sys.path.append(\"..\")\n",
    "from src.dataset import Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from definitions import *\n",
    "import copy\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Suppress LightGBM categorical_feature warning\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"categorical_feature keyword has been found*\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"categorical_feature in param dict is overridden*\")\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, precision_score, recall_score, balanced_accuracy_score\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset adult_fnlwgt_educational-num has ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country'] categorical and ['age', 'capital-gain', 'capital-loss', 'hours-per-week'] numerical columns.\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"adult\"\n",
    "\n",
    "protected_attributes_all = [\"sex\", \"race\", \"both\"]\n",
    "\n",
    "\n",
    "dataset_name_latex = \"\\\\\"+dataset_name\n",
    "\n",
    "\n",
    "if dataset_name==\"credit\":\n",
    "    dataset_name_latex += \"dataset\"\n",
    "dataset_generator = Dataset(dataset_name)\n",
    "all_data = dataset_generator.original_dataframe.copy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "arrays = np.load('../results/{}/arrays/arrays_all_models_all_fairness_metrics_protected_{}_small.npz'.format(dataset_name, \"_\".join(protected_attributes_all)))\n",
    "\n",
    "average = arrays['average'][2:3]\n",
    "std = arrays['std'][2:3]\n",
    "\n",
    "protected_attributes_all = [\"both\"]\n",
    "\n",
    "\n",
    "# average_over_problems = np.mean(average, axis=0)\n",
    "# std_over_problems = np.std(average, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\\\acc', '\\\\rocauc', '\\\\eqoddtable', '\\\\statpartable', '\\\\eqopptable']\n",
      "['max', 'max', 'min', 'min', 'min']\n",
      "[0, 2, 3, 4, 5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/panagiotou/Desktop/FairAugment/util/../src/dataset.py:691: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for attr_values, indices in dataframe.groupby(protected_attributes).groups.items():\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(21, 1, 5)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_types_map = [dataset_generator.dtype_map[col] for col in all_data.columns]\n",
    "\n",
    "# Check if all columns have the data type 'category'\n",
    "all_categorical = all(dtype == 'category' for dtype in column_types_map)\n",
    "\n",
    "# generative_methods = [\"tvae\", \"cart\", \"smote\"]\n",
    "generative_methods = [\"gaussian_copula\", \"ctgan\", \"tvae\", \"cart\", \"smote\"]\n",
    "\n",
    "if all_categorical:\n",
    "    print(\"Only categorical features, dropping SMOTE\")\n",
    "    generative_methods.remove(\"smote\")\n",
    "\n",
    "problem_classification = {\"metrics\":[accuracy_score, f1_score, roc_auc_score],\n",
    "                    \"metric_names\":[\"\\\\acc\", \"\\\\f1\", \"\\\\rocauc\"],\n",
    "                    \"fairness_metrics\": [eq_odd, stat_par, eq_opp],\n",
    "                    \"fairness_metric_names\": [\"Equalized odds\", \"Statistical Parity\", \"Equal Opportunity\"],\n",
    "                    \"fairness_metric_names\": [\"\\\\eqoddtable\",\"\\\\statpartable\", \"\\\\eqopptable\"],\n",
    "                    \"generative_methods\":generative_methods,\n",
    "                    \"sampling_methods\":['\\\\classonly', '\\\\classprotectedtable', '\\\\protectedonly', '\\\\sameclass']}\n",
    "\n",
    "\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "categorical_cols = dataset_generator.categorical_input_cols.copy()\n",
    "\n",
    "transformations = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, dataset_generator.continuous_input_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)])\n",
    "\n",
    "\n",
    "clf_RF = Pipeline(steps=[('preprocessor', transformations),\n",
    "                ('classifier', RandomForestClassifier(random_state=42))])\n",
    "clf_DT = Pipeline(steps=[('preprocessor', transformations),\n",
    "                    ('classifier', DecisionTreeClassifier(random_state=42))])     \n",
    "\n",
    "# clf_lgbm = Pipeline(steps=[('preprocessor', transformations_lgbm),\n",
    "#                     ('classifier', LGBMClassifier(categorical_feature=dataset_generator.categorical_input_col_locations, verbose=-1))])  \n",
    "\n",
    "                    \n",
    "# model_names_classification = [\"LightGBM\", \"XGBoost\", \"Decission Tree\", \"Random Forest\"]\n",
    "model_names_classification = [\"\\\\lgbm\", \"\\\\xgb\", \"\\\\dt\", \"\\\\rf\"]\n",
    "\n",
    "\n",
    "models_classification = [LGBMClassifier, xgb.XGBClassifier, clf_DT, clf_RF]\n",
    "\n",
    "\n",
    "\n",
    "args = [{\"categorical_feature\":dataset_generator.categorical_input_col_locations, \"verbose\":-1}, {\"enable_categorical\":True, \"tree_method\":'hist'}, {}, {}]\n",
    "\n",
    "problems_classification = []\n",
    "for model, name, arg in zip(models_classification, model_names_classification, args):\n",
    "    problem = problem_classification.copy()\n",
    "    problem[\"model\"] = copy.deepcopy(model)\n",
    "    problem[\"model_name\"] = name\n",
    "    problem[\"args\"] = arg\n",
    "    problems_classification.append(problem)\n",
    "\n",
    "\n",
    "metric_names_actual_all = [\"\\\\acc\", \"\\\\fone\", \"\\\\rocauc\", \"\\\\eqoddtable\",\"\\\\statpartable\", \"\\\\eqopptable\"]\n",
    "\n",
    "metrics_optimal_all = [\"max\", \"max\", \"max\", \"min\", \"min\", \"min\"]\n",
    "\n",
    "metrics_keep_all = [0, 2, 3, 4, 5]\n",
    "len_metrics_keep_all = len(metric_names_actual_all)\n",
    "\n",
    "\n",
    "names_train = [\"\\gaussiancopulatable\", \"\\ctgan\", \"\\\\tvae\", \"\\\\cart\", \"\\\\smote\"]\n",
    "\n",
    "if all_categorical:\n",
    "    print(\"Only categorical features, dropping SMOTE\")\n",
    "    names_train.remove(\"\\\\smote\")\n",
    "\n",
    "test_sets, _ = dataset_generator.split_population(all_data)\n",
    "# names_test = [f\"Sex={value}\" for value in test_sets.keys()]\n",
    "names_test = []\n",
    "names_test.append(\"Overall\")\n",
    "\n",
    "\n",
    "average_use = np.concatenate(average, axis=-1)[0]\n",
    "std_use = np.concatenate(std, axis=-1)[0]\n",
    "\n",
    "metric_names_actual = []\n",
    "metrics_optimal = []\n",
    "metrics_keep = []\n",
    "for pp, _ in enumerate(protected_attributes_all):\n",
    "    metric_names_actual.extend([metric_names_actual_all[i] for i in metrics_keep_all])\n",
    "    metrics_optimal.extend([metrics_optimal_all[i] for i in metrics_keep_all])\n",
    "    metrics_keep.extend([i + len_metrics_keep_all*pp for i in metrics_keep_all])\n",
    "\n",
    "print(metric_names_actual)\n",
    "print(metrics_optimal)\n",
    "print(metrics_keep)\n",
    "\n",
    "average_use = average_use[..., metrics_keep]\n",
    "std_use = std_use[..., metrics_keep]\n",
    "average_use.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table*}[h]\n",
      "\\caption{\\adult}\n",
      "\\label{tab:results_adult}\n",
      "\\centering\n",
      "\\begin{tabular}{l l c c c c c}\n",
      "\\hline\n",
      "\\samplingmethod & \\training & \\multicolumn{5}{c}{\\metrics} \\\\\n",
      "&  & \\multicolumn{5}{c}{both} \\\\\n",
      "& & \\acc & \\rocauc & \\eqoddtable & \\statpartable & \\eqopptable \\\\\n",
      "\\hline & \\multirow{1}{*}{Real} & \\textbf{0.867} & \\underline{0.798} & 0.205 & 0.221 & 0.131 \\\\\n",
      "\\hline\n",
      "\\multirow{5}{*}{\\classonly} & \\multirow{1}{*}{\\gaussiancopulatable} & 0.855 & 0.764 & 0.209 & \\cellcolor{blue!15}0.186 & 0.146 \\\\\n",
      " & \\multirow{1}{*}{\\ctgan} & 0.849 & 0.774 & \\cellcolor{blue!15}0.192 & \\cellcolor{blue!15}0.192 & \\cellcolor{blue!15}0.122 \\\\\n",
      " & \\multirow{1}{*}{\\tvae} & 0.848 & 0.773 & 0.242 & \\cellcolor{blue!15}0.213 & 0.153 \\\\\n",
      " & \\multirow{1}{*}{\\cart} & 0.835 & \\cellcolor{blue!15}\\textbf{0.817} & 0.222 & 0.243 & \\cellcolor{blue!15}\\underline{0.114} \\\\\n",
      " & \\multirow{1}{*}{\\smote} & 0.840 & 0.790 & 0.247 & 0.230 & 0.143 \\\\\n",
      "\\hline\n",
      "\\multirow{5}{*}{\\classprotectedtable} & \\multirow{1}{*}{\\gaussiancopulatable} & 0.850 & 0.757 & \\cellcolor{blue!15}0.188 & \\cellcolor{blue!15}0.182 & \\cellcolor{blue!15}0.122 \\\\\n",
      " & \\multirow{1}{*}{\\ctgan} & 0.834 & \\underline{0.798} & 0.211 & 0.235 & \\cellcolor{blue!15}\\textbf{0.110} \\\\\n",
      " & \\multirow{1}{*}{\\tvae} & 0.843 & 0.756 & 0.237 & \\cellcolor{blue!15}0.189 & 0.163 \\\\\n",
      " & \\multirow{1}{*}{\\cart} & 0.825 & 0.797 & 0.252 & 0.243 & 0.133 \\\\\n",
      " & \\multirow{1}{*}{\\smote} & 0.839 & 0.797 & 0.253 & 0.252 & 0.135 \\\\\n",
      "\\hline\n",
      "\\multirow{5}{*}{\\protectedonly} & \\multirow{1}{*}{\\gaussiancopulatable} & 0.841 & 0.752 & 0.219 & \\cellcolor{blue!15}0.169 & 0.168 \\\\\n",
      " & \\multirow{1}{*}{\\ctgan} & 0.853 & 0.763 & 0.267 & \\cellcolor{blue!15}0.213 & 0.188 \\\\\n",
      " & \\multirow{1}{*}{\\tvae} & 0.850 & 0.750 & 0.210 & \\cellcolor{blue!15}0.180 & 0.147 \\\\\n",
      " & \\multirow{1}{*}{\\cart} & \\underline{0.857} & 0.776 & 0.233 & \\cellcolor{blue!15}0.210 & 0.162 \\\\\n",
      " & \\multirow{1}{*}{\\smote} & 0.852 & 0.742 & 0.263 & \\cellcolor{blue!15}0.179 & 0.207 \\\\\n",
      "\\hline\n",
      "\\multirow{5}{*}{\\sameclass} & \\multirow{1}{*}{\\gaussiancopulatable} & 0.854 & 0.757 & \\cellcolor{blue!15}0.199 & \\cellcolor{blue!15}0.180 & 0.139 \\\\\n",
      " & \\multirow{1}{*}{\\ctgan} & 0.854 & 0.764 & \\cellcolor{blue!15}0.180 & \\cellcolor{blue!15}0.178 & \\cellcolor{blue!15}0.120 \\\\\n",
      " & \\multirow{1}{*}{\\tvae} & 0.855 & 0.764 & \\cellcolor{blue!15}\\underline{0.173} & \\cellcolor{blue!15}0.182 & \\cellcolor{blue!15}0.115 \\\\\n",
      " & \\multirow{1}{*}{\\cart} & 0.854 & 0.781 & \\cellcolor{blue!15}\\textbf{0.162} & \\cellcolor{blue!15}\\textbf{0.163} & \\cellcolor{blue!15}0.118 \\\\\n",
      " & \\multirow{1}{*}{\\smote} & 0.853 & 0.768 & \\cellcolor{blue!15}0.181 & \\cellcolor{blue!15}\\underline{0.167} & \\cellcolor{blue!15}0.128 \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n",
      "\\end{table*}\n"
     ]
    }
   ],
   "source": [
    "color_best_matrix = range(average_use.shape[-1])\n",
    "\n",
    "if \"both\" in protected_attributes_all or \"race\" in protected_attributes_all :\n",
    "    latex_table = generate_latex_table_max_all_methods_sex_race_both(average_use, std_use, names_train, names_test, problems_classification, protected_attributes_all, metric_names_actual=metric_names_actual, test_data=True, metrics_optimal=metrics_optimal, dataset_name=dataset_name_latex, longtable=False, color_best_matrix=color_best_matrix, include_std=False)\n",
    "else:\n",
    "    latex_table = generate_latex_table_max_all_methods_sex_race(average_use, std_use, names_train, names_test, problems_classification, protected_attributes_all, metric_names_actual=metric_names_actual, test_data=True, metrics_optimal=metrics_optimal, dataset_name=dataset_name_latex, longtable=False, color_best_matrix=color_best_matrix, include_std=False)\n",
    "print(latex_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "samplestructures",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
