{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append(\"..\")\n",
    "from src.dataset import Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from definitions import *\n",
    "import copy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Suppress LightGBM categorical_feature warning\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"categorical_feature keyword has been found*\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"categorical_feature in param dict is overridden*\")\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, precision_score, recall_score\n",
    "from fairlearn.metrics import demographic_parity_difference, demographic_parity_ratio, true_positive_rate_difference, true_positive_rate, false_positive_rate_difference\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "\n",
    "def eq_odd(y_test, y_pred, group_test):\n",
    "    return true_positive_rate_difference(y_test, y_pred, sensitive_features=group_test)\\\n",
    "                + false_positive_rate_difference(y_test, y_pred, sensitive_features=group_test)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset adult_fnlwgt_educational-num has ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'native-country'] categorical and ['age', 'capital-gain', 'capital-loss', 'hours-per-week'] numerical columns.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[0.869 0.716 0.838 0.223]\n",
      "[0.868 0.715 0.837 0.221]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/panagiotou/Desktop/FairAugment/util/../src/dataset.py:617: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for attr_values, indices in dataframe.groupby(protected_attributes).groups.items():\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 101\u001b[0m\n\u001b[1;32m     97\u001b[0m names_test \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     98\u001b[0m names_test\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOverall\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 101\u001b[0m latex_table \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_latex_table_max_all_methods\u001b[49m\u001b[43m(\u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnames_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnames_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproblems_classification\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_names_actual\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_names_actual\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics_optimal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics_optimal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_name_latex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28mprint\u001b[39m(latex_table)\n",
      "File \u001b[0;32m~/Desktop/FairAugment/util/definitions.py:132\u001b[0m, in \u001b[0;36mgenerate_latex_table_max_all_methods\u001b[0;34m(all_metrics_mean, all_metrics_std, names_train, names_test, problems, test_data, metric_names_actual, metrics_optimal, dataset_name)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# max_means = [0] * len(names_test)  # Initialize a list to store the maximum mean value for each column\u001b[39;00m\n\u001b[1;32m    128\u001b[0m latex_table \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m & & \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mmultirow\u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m*}\u001b[39m\u001b[38;5;132;01m{Real}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 132\u001b[0m max_of_each_column, min_of_each_column, second_max_of_each_column, second_min_of_each_column \u001b[38;5;241m=\u001b[39m \u001b[43mget_max_min\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_metrics_mean\u001b[49m\u001b[43m[\u001b[49m\u001b[43mproblem_i\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m max_of_each_column \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{:.3f}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m max_of_each_column]\n\u001b[1;32m    137\u001b[0m min_of_each_column \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{:.3f}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m min_of_each_column]\n",
      "File \u001b[0;32m~/Desktop/FairAugment/util/definitions.py:87\u001b[0m, in \u001b[0;36mget_max_min\u001b[0;34m(all_m)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28mprint\u001b[39m(max_of_each_column)\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28mprint\u001b[39m(second_max_of_each_column)\n\u001b[0;32m---> 87\u001b[0m \u001b[43mexit\u001b[49m(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# Select the second element in each column\u001b[39;00m\n\u001b[1;32m     89\u001b[0m second_max_of_each_column\u001b[38;5;241m=\u001b[39m sorted_arr_inv[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'exit' is not defined"
     ]
    }
   ],
   "source": [
    "dataset_name = \"adult\"\n",
    "\n",
    "\n",
    "dataset_name_latex = \"\\\\\"+dataset_name\n",
    "\n",
    "\n",
    "if dataset_name==\"credit\":\n",
    "    dataset_name_latex += \"dataset\"\n",
    "dataset_generator = Dataset(dataset_name)\n",
    "all_data = dataset_generator.original_dataframe.copy()\n",
    "\n",
    "\n",
    "print(\"\\n\\n\\n\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "arrays = np.load('../results/{}/arrays/arrays.npz'.format(dataset_name))\n",
    "average = arrays['average']\n",
    "std = arrays['std']\n",
    "    # feat_imp_average = arrays['feat_imp_average']\n",
    "    # feat_imp_std = arrays['feat_imp_std']\n",
    "\n",
    "    # feature_names = ['age', 'workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country']\n",
    "\n",
    "\n",
    "column_types_map = [dataset_generator.dtype_map[col] for col in all_data.columns]\n",
    "\n",
    "# Check if all columns have the data type 'category'\n",
    "all_categorical = all(dtype == 'category' for dtype in column_types_map)\n",
    "\n",
    "generative_methods = [\"tvae\", \"cart\", \"smote\"]\n",
    "# generative_methods = [\"gaussian_copula\", \"ctgan\", \"tvae\", \"cart\", \"smote\"]\n",
    "\n",
    "if all_categorical:\n",
    "    print(\"Only categorical features, dropping SMOTE\")\n",
    "    generative_methods.remove(\"smote\")\n",
    "\n",
    "problem_classification = {\"metrics\":[accuracy_score, f1_score, roc_auc_score],\n",
    "                    \"metric_names\":[\"\\\\acc\", \"\\\\f1\", \"\\\\rocauc\"],\n",
    "                    \"fairness_metrics\": [eq_odd],\n",
    "                    \"fairness_metric_names\": [\"\\\\eqodd\"],\n",
    "                    \"generative_methods\":generative_methods,\n",
    "                    \"sampling_methods\":['\\\\classonly', '\\\\classprotected', '\\\\protectedonly', '\\\\sameclass']}\n",
    "\n",
    "\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "categorical_cols = dataset_generator.categorical_input_cols.copy()\n",
    "\n",
    "transformations = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, dataset_generator.continuous_input_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)])\n",
    "\n",
    "\n",
    "clf_RF = Pipeline(steps=[('preprocessor', transformations),\n",
    "                ('classifier', RandomForestClassifier(random_state=42))])\n",
    "clf_DT = Pipeline(steps=[('preprocessor', transformations),\n",
    "                    ('classifier', DecisionTreeClassifier(random_state=42))])     \n",
    "\n",
    "# clf_lgbm = Pipeline(steps=[('preprocessor', transformations_lgbm),\n",
    "#                     ('classifier', LGBMClassifier(categorical_feature=dataset_generator.categorical_input_col_locations, verbose=-1))])  \n",
    "\n",
    "                    \n",
    "# model_names_classification = [\"LightGBM\", \"XGBoost\", \"Decission Tree\", \"Random Forest\"]\n",
    "model_names_classification = [\"\\\\lgbm\", \"\\\\xgb\", \"\\\\dt\", \"\\\\rf\"]\n",
    "\n",
    "\n",
    "models_classification = [LGBMClassifier, xgb.XGBClassifier, clf_DT, clf_RF]\n",
    "\n",
    "\n",
    "\n",
    "args = [{\"categorical_feature\":dataset_generator.categorical_input_col_locations, \"verbose\":-1}, {\"enable_categorical\":True, \"tree_method\":'hist'}, {}, {}]\n",
    "\n",
    "problems_classification = []\n",
    "for model, name, arg in zip(models_classification, model_names_classification, args):\n",
    "    problem = problem_classification.copy()\n",
    "    problem[\"model\"] = copy.deepcopy(model)\n",
    "    problem[\"model_name\"] = name\n",
    "    problem[\"args\"] = arg\n",
    "    problems_classification.append(problem)\n",
    "\n",
    "\n",
    "# metric_names_actual = [r\"Accuracy $\\uparrow$\", r\"F1 $\\uparrow$\", r\"ROC AUC $\\uparrow$\", r\"Equalized Odds $\\downarrow$\"]\n",
    "metric_names_actual = [\"\\\\acc\", \"\\\\fone\", \"\\\\rocauc\", \"\\\\eqodd\"]\n",
    "\n",
    "metrics_optimal = [\"max\", \"max\", \"max\", \"min\"]\n",
    "# names_train = [\"{}\".format(dataset_name), \"Augmented {} (TVAE)\".format(dataset_name), \"Augmented {} (CART)\".format(dataset_name), \"Augmented {} (SMOTENC)\".format(dataset_name)]\n",
    "\n",
    "names_train = [\"\\\\tvae\", \"\\\\cart\", \"\\\\smote\"]\n",
    "test_sets, _ = dataset_generator.split_population(all_data)\n",
    "protected_attributes = [\"Sex\"]\n",
    "# names_test = [f\"Sex={value}\" for value in test_sets.keys()]\n",
    "names_test = []\n",
    "names_test.append(\"Overall\")\n",
    "\n",
    "\n",
    "latex_table = generate_latex_table_max_all_methods(average, std, names_train, names_test, problems_classification, metric_names_actual=metric_names_actual, test_data=True, metrics_optimal=metrics_optimal, dataset_name=dataset_name_latex)\n",
    "print(latex_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "samplestructures",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
