{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append(\"..\")\n",
    "from src.dataset import Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from definitions import *\n",
    "import copy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Suppress LightGBM categorical_feature warning\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"categorical_feature keyword has been found*\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"categorical_feature in param dict is overridden*\")\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, precision_score, recall_score, balanced_accuracy_score\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset adult_fnlwgt_educational-num has ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country'] categorical and ['age', 'capital-gain', 'capital-loss', 'hours-per-week'] numerical columns.\n",
      "(4, 21, 1, 6)\n",
      "(21, 1, 6)\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"adult\"\n",
    "protected_attribute = \"race\"\n",
    "\n",
    "\n",
    "dataset_name_latex = \"\\\\\"+dataset_name\n",
    "\n",
    "\n",
    "if dataset_name==\"credit\":\n",
    "    dataset_name_latex += \"dataset\"\n",
    "dataset_generator = Dataset(dataset_name)\n",
    "all_data = dataset_generator.original_dataframe.copy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "arrays = np.load('../results/{}/arrays/arrays_all_models_all_fairness_metrics.npz'.format(dataset_name))\n",
    "average = arrays['average']\n",
    "# std = arrays['std']\n",
    "\n",
    "print(average.shape)\n",
    "average_over_problems = np.mean(average, axis=0)\n",
    "std_over_problems = np.std(average, axis=0)\n",
    "\n",
    "print(average_over_problems.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/panagiotou/Desktop/FairAugment/util/../src/dataset.py:641: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for attr_values, indices in dataframe.groupby(protected_attributes).groups.items():\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "column_types_map = [dataset_generator.dtype_map[col] for col in all_data.columns]\n",
    "\n",
    "# Check if all columns have the data type 'category'\n",
    "all_categorical = all(dtype == 'category' for dtype in column_types_map)\n",
    "\n",
    "# generative_methods = [\"tvae\", \"cart\", \"smote\"]\n",
    "generative_methods = [\"gaussian_copula\", \"ctgan\", \"tvae\", \"cart\", \"smote\"]\n",
    "\n",
    "if all_categorical:\n",
    "    print(\"Only categorical features, dropping SMOTE\")\n",
    "    generative_methods.remove(\"smote\")\n",
    "\n",
    "problem_classification = {\"metrics\":[accuracy_score, f1_score, roc_auc_score],\n",
    "                    \"metric_names\":[\"\\\\acc\", \"\\\\f1\", \"\\\\rocauc\"],\n",
    "                    \"fairness_metrics\": [eq_odd, stat_par, eq_opp],\n",
    "                    \"fairness_metric_names\": [\"Equalized odds\", \"Statistical Parity\", \"Equal Opportunity\"],\n",
    "                    \"fairness_metric_names\": [\"\\\\eqoddtable\",\"\\\\statpartable\", \"\\\\eqopptable\"],\n",
    "                    \"generative_methods\":generative_methods,\n",
    "                    \"sampling_methods\":['\\\\classonly', '\\\\classprotectedtable', '\\\\protectedonly', '\\\\sameclass']}\n",
    "\n",
    "\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "categorical_cols = dataset_generator.categorical_input_cols.copy()\n",
    "\n",
    "transformations = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, dataset_generator.continuous_input_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)])\n",
    "\n",
    "\n",
    "clf_RF = Pipeline(steps=[('preprocessor', transformations),\n",
    "                ('classifier', RandomForestClassifier(random_state=42))])\n",
    "clf_DT = Pipeline(steps=[('preprocessor', transformations),\n",
    "                    ('classifier', DecisionTreeClassifier(random_state=42))])     \n",
    "\n",
    "# clf_lgbm = Pipeline(steps=[('preprocessor', transformations_lgbm),\n",
    "#                     ('classifier', LGBMClassifier(categorical_feature=dataset_generator.categorical_input_col_locations, verbose=-1))])  \n",
    "\n",
    "                    \n",
    "# model_names_classification = [\"LightGBM\", \"XGBoost\", \"Decission Tree\", \"Random Forest\"]\n",
    "model_names_classification = [\"\\\\lgbm\", \"\\\\xgb\", \"\\\\dt\", \"\\\\rf\"]\n",
    "\n",
    "\n",
    "models_classification = [LGBMClassifier, xgb.XGBClassifier, clf_DT, clf_RF]\n",
    "\n",
    "\n",
    "\n",
    "args = [{\"categorical_feature\":dataset_generator.categorical_input_col_locations, \"verbose\":-1}, {\"enable_categorical\":True, \"tree_method\":'hist'}, {}, {}]\n",
    "\n",
    "problems_classification = []\n",
    "for model, name, arg in zip(models_classification, model_names_classification, args):\n",
    "    problem = problem_classification.copy()\n",
    "    problem[\"model\"] = copy.deepcopy(model)\n",
    "    problem[\"model_name\"] = name\n",
    "    problem[\"args\"] = arg\n",
    "    problems_classification.append(problem)\n",
    "\n",
    "\n",
    "# metric_names_actual = [r\"Accuracy $\\uparrow$\", r\"F1 $\\uparrow$\", r\"ROC AUC $\\uparrow$\", r\"Equalized Odds $\\downarrow$\"]\n",
    "metric_names_actual = [\"\\\\acc\", \"\\\\fone\", \"\\\\rocauc\", \"\\\\eqoddtable\",\"\\\\statpartable\", \"\\\\eqopptable\"]\n",
    "\n",
    "metrics_optimal = [\"max\", \"max\", \"max\", \"min\", \"min\", \"min\"]\n",
    "# names_train = [\"{}\".format(dataset_name), \"Augmented {} (TVAE)\".format(dataset_name), \"Augmented {} (CART)\".format(dataset_name), \"Augmented {} (SMOTENC)\".format(dataset_name)]\n",
    "\n",
    "names_train = [\"\\gaussiancopulatable\", \"\\ctgan\", \"\\\\tvae\", \"\\\\cart\", \"\\\\smote\"]\n",
    "\n",
    "if all_categorical:\n",
    "    print(\"Only categorical features, dropping SMOTE\")\n",
    "    names_train.remove(\"\\\\smote\")\n",
    "\n",
    "test_sets, _ = dataset_generator.split_population(all_data)\n",
    "# names_test = [f\"Sex={value}\" for value in test_sets.keys()]\n",
    "names_test = []\n",
    "names_test.append(\"Overall\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21, 1, 6)\n",
      "(6,)\n",
      "\\begin{table*}[h]\n",
      "\\caption{\\adult}\n",
      "\\label{tab:results_adult}\n",
      "\\centering\n",
      "\\begin{tabular}{l l c c c c c c}\n",
      "\\hline\n",
      "\\samplingmethod & \\training & \\multicolumn{6}{c}{\\metrics} \\\\\n",
      "\\cline{3-8}&  & \\acc & \\fone & \\rocauc & \\eqoddtable & \\statpartable & \\eqopptable \\\\\n",
      "\\hline & \\multirow{1}{*}{Real} & \\textbf{0.849} & \\textbf{0.678} & 0.778 & 0.137 & 0.180 & 0.062 \\\\\n",
      "\\hline\n",
      "\\hline\n",
      "\\multirow{5}{*}{\\classonly} & \\multirow{1}{*}{\\gaussiancopulatable} & 0.844 & 0.666 & 0.772 & \\cellcolor{blue!15}0.123 & \\cellcolor{blue!15}0.174 & \\cellcolor{blue!15}0.051 \\\\\n",
      " & \\multirow{1}{*}{\\ctgan} & 0.837 & \\underline{0.676} & \\cellcolor{blue!15}0.786 & \\cellcolor{blue!15}0.128 & 0.188 & \\cellcolor{blue!15}0.044 \\\\\n",
      " & \\multirow{1}{*}{\\tvae} & 0.835 & 0.668 & \\cellcolor{blue!15}0.782 & 0.154 & 0.198 & \\cellcolor{blue!15}0.058 \\\\\n",
      " & \\multirow{1}{*}{\\cart} & 0.818 & 0.674 & \\cellcolor{blue!15}\\textbf{0.799} & \\cellcolor{blue!15}0.119 & 0.193 & \\cellcolor{blue!15}\\underline{0.025} \\\\\n",
      " & \\multirow{1}{*}{\\smote} & 0.826 & 0.670 & \\cellcolor{blue!15}0.791 & \\cellcolor{blue!15}0.124 & 0.197 & \\cellcolor{blue!15}0.026 \\\\\n",
      "\\hline\n",
      "\\multirow{5}{*}{\\classprotectedtable} & \\multirow{1}{*}{\\gaussiancopulatable} & 0.843 & 0.664 & 0.770 & \\cellcolor{blue!15}0.136 & \\cellcolor{blue!15}0.176 & \\cellcolor{blue!15}0.061 \\\\\n",
      " & \\multirow{1}{*}{\\ctgan} & 0.838 & 0.673 & \\cellcolor{blue!15}0.782 & 0.154 & 0.190 & 0.069 \\\\\n",
      " & \\multirow{1}{*}{\\tvae} & 0.835 & 0.668 & \\cellcolor{blue!15}0.781 & 0.190 & 0.207 & 0.088 \\\\\n",
      " & \\multirow{1}{*}{\\cart} & 0.816 & 0.671 & \\cellcolor{blue!15}\\underline{0.798} & \\cellcolor{blue!15}0.118 & 0.192 & \\cellcolor{blue!15}\\underline{0.025} \\\\\n",
      " & \\multirow{1}{*}{\\smote} & 0.826 & 0.670 & \\cellcolor{blue!15}0.792 & \\cellcolor{blue!15}0.135 & 0.201 & \\cellcolor{blue!15}0.035 \\\\\n",
      "\\hline\n",
      "\\multirow{5}{*}{\\protectedonly} & \\multirow{1}{*}{\\gaussiancopulatable} & 0.842 & 0.653 & 0.762 & 0.168 & \\cellcolor{blue!15}0.174 & 0.098 \\\\\n",
      " & \\multirow{1}{*}{\\ctgan} & 0.846 & 0.662 & 0.768 & 0.140 & \\cellcolor{blue!15}0.173 & 0.069 \\\\\n",
      " & \\multirow{1}{*}{\\tvae} & 0.846 & 0.666 & 0.770 & \\cellcolor{blue!15}0.135 & \\cellcolor{blue!15}0.174 & 0.064 \\\\\n",
      " & \\multirow{1}{*}{\\cart} & 0.846 & 0.662 & 0.768 & \\cellcolor{blue!15}0.136 & \\cellcolor{blue!15}0.173 & 0.066 \\\\\n",
      " & \\multirow{1}{*}{\\smote} & \\underline{0.847} & 0.663 & 0.767 & 0.201 & 0.187 & 0.122 \\\\\n",
      "\\hline\n",
      "\\multirow{5}{*}{\\sameclass} & \\multirow{1}{*}{\\gaussiancopulatable} & 0.846 & 0.666 & 0.771 & \\cellcolor{blue!15}0.119 & \\cellcolor{blue!15}0.170 & \\cellcolor{blue!15}0.049 \\\\\n",
      " & \\multirow{1}{*}{\\ctgan} & 0.845 & 0.671 & 0.775 & \\cellcolor{blue!15}0.096 & \\cellcolor{blue!15}0.165 & \\cellcolor{blue!15}0.032 \\\\\n",
      " & \\multirow{1}{*}{\\tvae} & 0.845 & 0.665 & 0.772 & \\cellcolor{blue!15}\\textbf{0.087} & \\cellcolor{blue!15}0.161 & \\cellcolor{blue!15}\\textbf{0.024} \\\\\n",
      " & \\multirow{1}{*}{\\cart} & 0.841 & 0.667 & 0.775 & \\cellcolor{blue!15}0.106 & \\cellcolor{blue!15}\\textbf{0.138} & \\cellcolor{blue!15}0.060 \\\\\n",
      " & \\multirow{1}{*}{\\smote} & 0.842 & 0.665 & 0.773 & \\cellcolor{blue!15}\\underline{0.088} & \\cellcolor{blue!15}\\underline{0.145} & \\cellcolor{blue!15}0.037 \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n",
      "\\end{table*}\n"
     ]
    }
   ],
   "source": [
    "color_best_matrix = [0, 1, 2, 3, 4, 5]\n",
    "\n",
    "latex_table = generate_latex_table_max_all_methods_avg_problems(average_over_problems, std_over_problems, names_train, names_test, problems_classification, metric_names_actual=metric_names_actual, test_data=True, metrics_optimal=metrics_optimal, dataset_name=dataset_name_latex, longtable=False, color_best_matrix=color_best_matrix, include_std=False)\n",
    "print(latex_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "samplestructures",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
